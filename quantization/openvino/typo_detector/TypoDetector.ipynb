{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e770bdc-4999-4827-a2b1-61903bf22623",
   "metadata": {},
   "source": [
    "# Typo Detector with OpenVINO\n",
    "Typo detection in AI is a process of identifying and correcting typographical errors in text data using machine learning algorithms. The goal of typo detection is to improve the accuracy, readability, and usability of text by identifying and indicating mistakes made during the writing process. To detect typos, AI-based typo detectors use various techniques, such as natural language processing (NLP), machine learning (ML), and deep learning (DL).\n",
    "\n",
    "A typo detector takes a sentence as an input and identify all typographical errors such as misspellings and homophone errors.\n",
    "\n",
    "This tutorial provides how to use the Typo Detector from the Hugging Face Transformers library in the OpenVINO environment to perform the above task.\n",
    "\n",
    "The model detects typos in a given text with a high accuracy, performances of which are listed below,\n",
    "\n",
    "- Precision score of 0.9923\n",
    "- Recall score of 0.9859\n",
    "- f1-score of 0.9891\n",
    "\n",
    "https://huggingface.co/m3hrdadfi/typo-detector-distilbert-en\n",
    "\n",
    "These metrics indicate that the model can correctly identify a high proportion of both correct and incorrect text, minimizing both false positives and false negatives.\n",
    "\n",
    "The model has been pretrained on the NeuSpell dataset. https://github.com/neuspell/neuspell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d4d39-d8f8-4c71-8988-bdcca34ca26c",
   "metadata": {},
   "source": [
    "# Pip packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700af8ec-5a9a-4765-aeea-dcce57f15522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q \"diffusers>=0.17.1\" \"openvino>=2023.1.0\" \"nncf>=2.5.0\" \"gradio>=4.19\" \"onnx>=1.11.0,<1.16.2\" \"transformers>=4.39.0\" \"torch>=2.1,<2.4\" \"torchvision<0.19.0\" --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "#%pip install -q \"git+https://github.com/huggingface/optimum-intel.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b925e284-8116-4b55-a125-d247abdbe1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline,\n",
    ")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc06771-1504-4da9-8554-fbe381f5d24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03fb9376633497aac777e7504ba2e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', index=1, options=('CPU', 'AUTO'), value='AUTO')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebook_utils import device_widget\n",
    "\n",
    "device = device_widget()\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61efd86-1d58-41a8-ba46-b077ea9841a5",
   "metadata": {},
   "source": [
    "# Using Hugging Face Optimum Intel library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e820ca5-984f-439a-ae20-d54c163de742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddb8a1a314042e0a802ec0955e3de32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework not specified. Using pt to export the model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3178c6fe994349996c48788981b49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f56eeef1c6043dfac07532bc8efebfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/365 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa07268395f48f7b5c07d907501d913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db63a6da7fe4d6ca165efa5d262f72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08524cc48ab454a988ce5bcbd8c97ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using framework PyTorch: 2.4.0+cu121\n",
      "/home/olonok/miniforge3/envs/openvino/lib/python3.11/site-packages/nncf/torch/dynamic_graph/wrappers.py:86: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  op1 = operator(*args, **kwargs)\n",
      "Compiling the model to AUTO ...\n"
     ]
    }
   ],
   "source": [
    "from optimum.intel.openvino import OVModelForTokenClassification\n",
    "# The pretrained model we are using\n",
    "model_id = \"m3hrdadfi/typo-detector-distilbert-en\"\n",
    "\n",
    "model_dir = Path(\"typo_detector\")\n",
    "\n",
    "# Save the model to the path if not existing\n",
    "if model_dir.exists():\n",
    "    model = OVModelForTokenClassification.from_pretrained(model_dir, device=device.value)\n",
    "else:\n",
    "    model = OVModelForTokenClassification.from_pretrained(model_id, export=True, device=device.value)\n",
    "    model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f08cdd3-a407-4049-a024-19ddf2a1b9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "nlp = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"average\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d38c0a15-3192-4f40-9361-40cc00df20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_typos(sentence: str):\n",
    "    \"\"\"\n",
    "    Detect typos from the given sentence.\n",
    "    Writes both the original input and typo-tagged version to the terminal.\n",
    "\n",
    "    Arguments:\n",
    "    sentence -- Sentence to be evaluated (string)\n",
    "    \"\"\"\n",
    "\n",
    "    typos = [sentence[r[\"start\"] : r[\"end\"]] for r in nlp(sentence)]\n",
    "\n",
    "    detected = \"\\033[1;30m\"+sentence\n",
    "    for typo in typos:\n",
    "        detected = detected.replace(typo, f\"\\033[1;31;47m <i>{typo}</i>\\033[0m\\033[1;30m\")\n",
    "\n",
    "    print(\"\\033[1;30m[Input]: \",  sentence)\n",
    "    print(\"[Detected]: \", detected)\n",
    "    print(\"-\" * 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3df5f94-e655-4ead-ac6b-40542a50414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m   [Input]:  He had also stgruggled with addiction during his time in Congress .\n",
      "[Detected]:  \u001b[1;30mHe had also \u001b[1;31;47m <i>stgruggled</i>\u001b[0m\u001b[1;30m with addiction during his time in Congress .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  The review thoroughla assessed all aspects of JLENS SuR and CPG esign maturit and confidence .\n",
      "[Detected]:  \u001b[1;30mThe review \u001b[1;31;47m <i>thoroughla</i>\u001b[0m\u001b[1;30m assessed all aspects of JLENS SuR and CPG \u001b[1;31;47m <i>esign</i>\u001b[0m\u001b[1;30m \u001b[1;31;47m <i>maturit</i>\u001b[0m\u001b[1;30m and confidence .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  Letterma also apologized two his staff for the satyation .\n",
      "[Detected]:  \u001b[1;30m\u001b[1;31;47m <i>Letterma</i>\u001b[0m\u001b[1;30m also apologized \u001b[1;31;47m <i>two</i>\u001b[0m\u001b[1;30m his staff for the \u001b[1;31;47m <i>satyation</i>\u001b[0m\u001b[1;30m .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  Vincent Jay had earlier won France 's first gold in gthe 10km biathlon sprint .\n",
      "[Detected]:  \u001b[1;30mVincent Jay had earlier won France 's first gold in \u001b[1;31;47m <i>gthe</i>\u001b[0m\u001b[1;30m 10km biathlon sprint .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  It is left to the directors to figure out hpw to bring the stry across to tye audience .\n",
      "[Detected]:  \u001b[1;30mIt is left to the directors to figure out \u001b[1;31;47m <i>hpw</i>\u001b[0m\u001b[1;30m to bring the \u001b[1;31;47m <i>stry</i>\u001b[0m\u001b[1;30m across to \u001b[1;31;47m <i>tye</i>\u001b[0m\u001b[1;30m audience .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  I wnet to the park yestreday to play foorball with my fiends, but it statred to rain very hevaily and we had to stop.\n",
      "[Detected]:  \u001b[1;30mI \u001b[1;31;47m <i>wnet</i>\u001b[0m\u001b[1;30m to the park \u001b[1;31;47m <i>yestreday</i>\u001b[0m\u001b[1;30m to play \u001b[1;31;47m <i>foorball</i>\u001b[0m\u001b[1;30m with my \u001b[1;31;47m <i>fiends</i>\u001b[0m\u001b[1;30m, but it \u001b[1;31;47m <i>statred</i>\u001b[0m\u001b[1;30m to rain very \u001b[1;31;47m <i>hevaily</i>\u001b[0m\u001b[1;30m and we had to stop.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  My faorite restuarant servs the best spahgetti in the town, but they are always so buzy that you have to make a resrvation in advnace.\n",
      "[Detected]:  \u001b[1;30mMy \u001b[1;31;47m <i>faorite</i>\u001b[0m\u001b[1;30m \u001b[1;31;47m <i>restuarant</i>\u001b[0m\u001b[1;30m \u001b[1;31;47m <i>servs</i>\u001b[0m\u001b[1;30m the best \u001b[1;31;47m <i>spahgetti</i>\u001b[0m\u001b[1;30m in the town, but they are always so \u001b[1;31;47m <i>buzy</i>\u001b[0m\u001b[1;30m that you have to make a \u001b[1;31;47m <i>resrvation</i>\u001b[0m\u001b[1;30m in \u001b[1;31;47m <i>advnace</i>\u001b[0m\u001b[1;30m.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  I was goig to watch a mvoie on Netflx last night, but the straming was so slow that I decided to cancled my subscrpition.\n",
      "[Detected]:  \u001b[1;30mI was \u001b[1;31;47m <i>goig</i>\u001b[0m\u001b[1;30m to watch a \u001b[1;31;47m <i>mvoie</i>\u001b[0m\u001b[1;30m on \u001b[1;31;47m <i>Netflx</i>\u001b[0m\u001b[1;30m last night, but the \u001b[1;31;47m <i>straming</i>\u001b[0m\u001b[1;30m was so slow that I decided to \u001b[1;31;47m <i>cancled</i>\u001b[0m\u001b[1;30m my \u001b[1;31;47m <i>subscrpition</i>\u001b[0m\u001b[1;30m.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  My freind and I went campign in the forest last weekend and saw a beutiful sunst that was so amzing it took our breth away.\n",
      "[Detected]:  \u001b[1;30mMy \u001b[1;31;47m <i>freind</i>\u001b[0m\u001b[1;30m and I went \u001b[1;31;47m <i>campign</i>\u001b[0m\u001b[1;30m in the forest last weekend and saw a \u001b[1;31;47m <i>beutiful</i>\u001b[0m\u001b[1;30m \u001b[1;31;47m <i>sunst</i>\u001b[0m\u001b[1;30m that was so \u001b[1;31;47m <i>amzing</i>\u001b[0m\u001b[1;30m it took our \u001b[1;31;47m <i>breth</i>\u001b[0m\u001b[1;30m away.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  I  have been stuying for my math exam all week, but I'm stil not very confidet that I will pass it, because there are so many formuals to remeber.\n",
      "[Detected]:  \u001b[1;30mI  have been \u001b[1;31;47m <i>stuying</i>\u001b[0m\u001b[1;30m for my math exam all week, but I'm \u001b[1;31;47m <i>stil</i>\u001b[0m\u001b[1;30m not very \u001b[1;31;47m <i>confidet</i>\u001b[0m\u001b[1;30m that I will pass it, because there are so many formuals to \u001b[1;31;47m <i>remeber</i>\u001b[0m\u001b[1;30m.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Time elapsed: 0.3823058605194092\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"He had also stgruggled with addiction during his time in Congress .\",\n",
    "    \"The review thoroughla assessed all aspects of JLENS SuR and CPG esign maturit and confidence .\",\n",
    "    \"Letterma also apologized two his staff for the satyation .\",\n",
    "    \"Vincent Jay had earlier won France 's first gold in gthe 10km biathlon sprint .\",\n",
    "    \"It is left to the directors to figure out hpw to bring the stry across to tye audience .\",\n",
    "    \"I wnet to the park yestreday to play foorball with my fiends, but it statred to rain very hevaily and we had to stop.\",\n",
    "    \"My faorite restuarant servs the best spahgetti in the town, but they are always so buzy that you have to make a resrvation in advnace.\",\n",
    "    \"I was goig to watch a mvoie on Netflx last night, but the straming was so slow that I decided to cancled my subscrpition.\",\n",
    "    \"My freind and I went campign in the forest last weekend and saw a beutiful sunst that was so amzing it took our breth away.\",\n",
    "    \"I  have been stuying for my math exam all week, but I'm stil not very confidet that I will pass it, because there are so many formuals to remeber.\",\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sentence in sentences:\n",
    "    show_typos(sentence)\n",
    "\n",
    "print(f\"Time elapsed: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72367d1-846b-46be-8267-55885b26a747",
   "metadata": {},
   "source": [
    "# Converting the model to OpenVINO IR\n",
    "Use the AutoModelForTokenClassification class to load the pretrained pytorch model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e45a3f7-e4ad-4b31-879e-ac91454765c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"m3hrdadfi/typo-detector-distilbert-en\"\n",
    "model_dir = Path(\"pytorch_model\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "\n",
    "# Save the model to the path if not existing\n",
    "if model_dir.exists():\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
    "else:\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_id, config=config)\n",
    "    model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c91d8316-8424-4cc8-9282-5b83dde10aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "\n",
    "ov_model_path = Path(model_dir) / \"typo_detect.xml\"\n",
    "\n",
    "dummy_model_input = tokenizer(\"This is a sample\", return_tensors=\"pt\")\n",
    "ov_model = ov.convert_model(model, example_input=dict(dummy_model_input))\n",
    "ov.save_model(ov_model, ov_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90df5810-e58c-44c6-a715-989764a2dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "\n",
    "compiled_model = core.compile_model(ov_model, device.value)\n",
    "output_layer = compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819f78f-aa96-4d35-b7ef-a289bbf028e3",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7b28a38-594e-4fb2-8a7e-48270cf6fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_words(tokens: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Maps the list of tokens to words in the original text.\n",
    "    Built on the feature that tokens starting with '##' is attached to the previous token as tokens derived from the same word.\n",
    "\n",
    "    Arguments:\n",
    "    tokens -- List of tokens\n",
    "\n",
    "    Returns:\n",
    "    map_to_words -- Dictionary mapping tokens to words in original text\n",
    "    \"\"\"\n",
    "\n",
    "    word_count = -1\n",
    "    map_to_words = {}\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"##\"):\n",
    "            map_to_words[token] = word_count\n",
    "            continue\n",
    "        word_count += 1\n",
    "        map_to_words[token] = word_count\n",
    "    return map_to_words\n",
    "\n",
    "def infer(input_text: str) -> Dict[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Creating a generic inference function to read the input and infer the result\n",
    "\n",
    "    Arguments:\n",
    "    input_text -- The text to be infered (String)\n",
    "\n",
    "    Returns:\n",
    "    result -- Resulting list from inference\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    inputs = dict(tokens)\n",
    "    result = compiled_model(inputs)[output_layer]\n",
    "    return result\n",
    "\n",
    "def get_typo_indexes(\n",
    "    result: Dict[np.ndarray, np.ndarray],\n",
    "    map_to_words: Dict[str, int],\n",
    "    tokens: List[str],\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Given results from the inference and tokens-map-to-words, identifies the indexes of the words with typos.\n",
    "\n",
    "    Arguments:\n",
    "    result -- Result from inference (tensor)\n",
    "    map_to_words -- Dictionary mapping tokens to words (Dictionary)\n",
    "\n",
    "    Results:\n",
    "    wrong_words -- List of indexes of words with typos\n",
    "    \"\"\"\n",
    "\n",
    "    wrong_words = []\n",
    "    c = 0\n",
    "    result_list = result[0][1:-1]\n",
    "    for i in result_list:\n",
    "        prob = np.argmax(i)\n",
    "        if prob == 1:\n",
    "            if map_to_words[tokens[c]] not in wrong_words:\n",
    "                wrong_words.append(map_to_words[tokens[c]])\n",
    "        c += 1\n",
    "    return wrong_words\n",
    "\n",
    "def sentence_split(sentence: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split the sentence into words and characters\n",
    "\n",
    "    Arguments:\n",
    "    sentence - Sentence to be split (string)\n",
    "\n",
    "    Returns:\n",
    "    splitted -- List of words and characters\n",
    "    \"\"\"\n",
    "\n",
    "    splitted = re.split(\"([',. ])\", sentence)\n",
    "    splitted = [x for x in splitted if x != \" \" and x != \"\"]\n",
    "    return splitted\n",
    "\n",
    "\n",
    "def show_typos(sentence: str):\n",
    "    \"\"\"\n",
    "    Detect typos from the given sentence.\n",
    "    Writes both the original input and typo-tagged version to the terminal.\n",
    "\n",
    "    Arguments:\n",
    "    sentence -- Sentence to be evaluated (string)\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    map_to_words = token_to_words(tokens)\n",
    "    result = infer(sentence)\n",
    "    typo_indexes = get_typo_indexes(result, map_to_words, tokens)\n",
    "\n",
    "    sentence_words = sentence_split(sentence)\n",
    "\n",
    "    typos = [sentence_words[i] for i in typo_indexes]\n",
    "\n",
    "    detected = \"\\033[1;30m\"+sentence\n",
    "    for typo in typos:\n",
    "        detected = detected.replace(typo, f\"\\033[1;31;47m <i>{typo}</i>\\033[0m\\033[1;30m\")\n",
    "\n",
    "    print(\"\\033[1;30m   [Input]: \", sentence)\n",
    "    print(\"[Detected]: \", detected)\n",
    "    print(\"-\" * 130)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04fca335-194f-462f-934f-93d7b2188056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m   [Input]:  He had also stgruggled with addiction during his time in Congress .\n",
      "[Detected]:  \u001b[1;30mHe had also \u001b[1;31;47m <i>stgruggled</i>\u001b[0m\u001b[1;30m with addiction during his time in Congress .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  The review thoroughla assessed all aspects of JLENS SuR and CPG esign maturit and confidence .\n",
      "[Detected]:  \u001b[1;30mThe review \u001b[1;31;47m <i>thoroughla</i>\u001b[0m\u001b[1;30m assessed all aspects of JLENS SuR and CPG \u001b[1;31;47m <i>esign</i>\u001b[0m\u001b[1;30m \u001b[1;31;47m <i>maturit</i>\u001b[0m\u001b[1;30m and confidence .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  Letterma also apologized two his staff for the satyation .\n",
      "[Detected]:  \u001b[1;30m\u001b[1;31;47m <i>Letterma</i>\u001b[0m\u001b[1;30m also apologized \u001b[1;31;47m <i>two</i>\u001b[0m\u001b[1;30m his staff for the \u001b[1;31;47m <i>satyation</i>\u001b[0m\u001b[1;30m .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  Vincent Jay had earlier won France 's first gold in gthe 10km biathlon sprint .\n",
      "[Detected]:  \u001b[1;30mVincent Jay had earlier won France 's first gold in \u001b[1;31;47m <i>gthe</i>\u001b[0m\u001b[1;30m 10km biathlon sprint .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  It is left to the directors to figure out hpw to bring the stry across to tye audience .\n",
      "[Detected]:  \u001b[1;30mIt is left to the directors to figure out \u001b[1;31;47m <i>hpw</i>\u001b[0m\u001b[1;30m to bring the \u001b[1;31;47m <i>stry</i>\u001b[0m\u001b[1;30m across to \u001b[1;31;47m <i>tye</i>\u001b[0m\u001b[1;30m audience .\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  I wnet to the park yestreday to play foorball with my fiends, but it statred to rain very hevaily and we had to stop.\n",
      "[Detected]:  \u001b[1;30mI \u001b[1;31;47m <i>wnet</i>\u001b[0m\u001b[1;30m to the park \u001b[1;31;47m <i>yestreday</i>\u001b[0m\u001b[1;30m to play \u001b[1;31;47m <i>foorball</i>\u001b[0m\u001b[1;30m with my \u001b[1;31;47m <i>fiends</i>\u001b[0m\u001b[1;30m, but it \u001b[1;31;47m <i>statred</i>\u001b[0m\u001b[1;30m to rain very \u001b[1;31;47m <i>hevaily</i>\u001b[0m\u001b[1;30m and we had to stop.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  My faorite restuarant servs the best spahgetti in the town, but they are always so buzy that you have to make a resrvation in advnace.\n",
      "[Detected]:  \u001b[1;30mMy \u001b[1;31;47m <i>faorite</i>\u001b[0m\u001b[1;30m \u001b[1;31;47m <i>restuarant</i>\u001b[0m\u001b[1;30m \u001b[1;31;47m <i>servs</i>\u001b[0m\u001b[1;30m the best \u001b[1;31;47m <i>spahgetti</i>\u001b[0m\u001b[1;30m in the town, but they are always so \u001b[1;31;47m <i>buzy</i>\u001b[0m\u001b[1;30m that you have to make a \u001b[1;31;47m <i>resrvation</i>\u001b[0m\u001b[1;30m in \u001b[1;31;47m <i>advnace</i>\u001b[0m\u001b[1;30m.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  I was goig to watch a mvoie on Netflx last night, but the straming was so slow that I decided to cancled my subscrpition.\n",
      "[Detected]:  \u001b[1;30mI was \u001b[1;31;47m <i>goig</i>\u001b[0m\u001b[1;30m to watch a \u001b[1;31;47m <i>mvoie</i>\u001b[0m\u001b[1;30m on \u001b[1;31;47m <i>Netflx</i>\u001b[0m\u001b[1;30m last night, but the \u001b[1;31;47m <i>straming</i>\u001b[0m\u001b[1;30m was so slow that I decided to \u001b[1;31;47m <i>cancled</i>\u001b[0m\u001b[1;30m my \u001b[1;31;47m <i>subscrpition</i>\u001b[0m\u001b[1;30m.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  My freind and I went campign in the forest last weekend and saw a beutiful sunst that was so amzing it took our breth away.\n",
      "[Detected]:  \u001b[1;30mMy \u001b[1;31;47m <i>freind</i>\u001b[0m\u001b[1;30m and I went \u001b[1;31;47m <i>campign</i>\u001b[0m\u001b[1;30m in the forest last weekend and saw a \u001b[1;31;47m <i>beutiful</i>\u001b[0m\u001b[1;30m \u001b[1;31;47m <i>sunst</i>\u001b[0m\u001b[1;30m that was so \u001b[1;31;47m <i>amzing</i>\u001b[0m\u001b[1;30m it took our \u001b[1;31;47m <i>breth</i>\u001b[0m\u001b[1;30m away.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1;30m   [Input]:  I  have been stuying for my math exam all week, but I'm stil not very confidet that I will pass it, because there are so many formuals to remeber.\n",
      "[Detected]:  \u001b[1;30mI  have been \u001b[1;31;47m <i>stuying</i>\u001b[0m\u001b[1;30m for my math exam all week, but I'm \u001b[1;31;47m <i>stil</i>\u001b[0m\u001b[1;30m not very \u001b[1;31;47m <i>confidet</i>\u001b[0m\u001b[1;30m that I will pass it, because there are so many formuals to \u001b[1;31;47m <i>remeber</i>\u001b[0m\u001b[1;30m.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Time elapsed: 0.4181959629058838\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"He had also stgruggled with addiction during his time in Congress .\",\n",
    "    \"The review thoroughla assessed all aspects of JLENS SuR and CPG esign maturit and confidence .\",\n",
    "    \"Letterma also apologized two his staff for the satyation .\",\n",
    "    \"Vincent Jay had earlier won France 's first gold in gthe 10km biathlon sprint .\",\n",
    "    \"It is left to the directors to figure out hpw to bring the stry across to tye audience .\",\n",
    "    \"I wnet to the park yestreday to play foorball with my fiends, but it statred to rain very hevaily and we had to stop.\",\n",
    "    \"My faorite restuarant servs the best spahgetti in the town, but they are always so buzy that you have to make a resrvation in advnace.\",\n",
    "    \"I was goig to watch a mvoie on Netflx last night, but the straming was so slow that I decided to cancled my subscrpition.\",\n",
    "    \"My freind and I went campign in the forest last weekend and saw a beutiful sunst that was so amzing it took our breth away.\",\n",
    "    \"I  have been stuying for my math exam all week, but I'm stil not very confidet that I will pass it, because there are so many formuals to remeber.\",\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for sentence in sentences:\n",
    "    show_typos(sentence)\n",
    "\n",
    "print(f\"Time elapsed: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c465e13-7a5d-4030-bdc4-04f66a10e380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (openvino)",
   "language": "python",
   "name": "openvino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
