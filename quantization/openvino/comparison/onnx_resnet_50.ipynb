{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e25d53e-c30d-49e4-9ab5-11c5b90511d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, datasets, transforms as T\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03390910-6c8a-48aa-9f8c-54874694cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights=ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc5463d-6b09-47d5-98f9-c4a992d142fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing for ResNet-50 Inferencing, from https://pytorch.org/hub/pytorch_vision_resnet/\n",
    "resnet50.eval()  \n",
    "filename = 'buterfly.jpg' # change to your filename\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b036706a-20a0-4987-ac4a-4155dec208bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export the model to ONNX\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "x = torch.randn(1, 3, image_height, image_width, requires_grad=True)\n",
    "torch_out = resnet50(x)\n",
    "torch.onnx.export(resnet50,                     # model being run\n",
    "                  x,                            # model input (or a tuple for multiple inputs)\n",
    "                  \"resnet50.onnx\",              # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,           # store the trained parameter weights inside the model file\n",
    "                  opset_version=12,             # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,     # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],      # the model's input names\n",
    "                  output_names = ['output'])    # the model's output names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d830ad-20e2-4fc0-8fb4-c85af763647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference with ONNX Runtime\n",
    "import onnxruntime\n",
    "from onnx import numpy_helper\n",
    "import time\n",
    "\n",
    "session_fp32 = onnxruntime.InferenceSession(\"resnet50.onnx\", providers=['CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fdcbe9c-469d-4f74-a20f-c4dba4a773d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d644331-5297-4c42-8694-ebed4ff06e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "latency = []\n",
    "def run_sample(session, image_file, categories, inputs):\n",
    "    start = time.time()\n",
    "    input_arr = inputs.cpu().detach().numpy()\n",
    "    ort_outputs = session.run([], {'input':input_arr})[0]\n",
    "    latency.append(time.time() - start)\n",
    "    output = ort_outputs.flatten()\n",
    "    output = softmax(output) # this is optional\n",
    "    top5_catid = np.argsort(-output)[:5]\n",
    "    results= []\n",
    "    for catid in top5_catid:\n",
    "        print(categories[catid], output[catid])\n",
    "        r = {\n",
    "                \"label\": categories[catid],\n",
    "                \"probability\": output[catid],\n",
    "            }\n",
    "        results.append(r)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15247f47-3a8d-4f70-9c48-f451f39b2fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ringlet 0.29918912\n",
      "monarch 0.0960618\n",
      "admiral 0.06821007\n",
      "lycaenid 0.013846645\n",
      "sulphur butterfly 0.008360029\n"
     ]
    }
   ],
   "source": [
    "ort_output = run_sample(session_fp32, 'buterfly.jpg', categories, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb51863-cbda-48d0-8afc-2aa394a90002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ringlet', 'probability': 0.29918912},\n",
       " {'label': 'monarch', 'probability': 0.0960618},\n",
       " {'label': 'admiral', 'probability': 0.06821007},\n",
       " {'label': 'lycaenid', 'probability': 0.013846645},\n",
       " {'label': 'sulphur butterfly', 'probability': 0.008360029}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8121f33-c600-45c3-ab51-1f4a2dbfd63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ox 0.40344307\n",
      "bison 0.040098358\n",
      "bighorn 0.016780484\n",
      "water buffalo 0.01569149\n",
      "hog 0.009256917\n"
     ]
    }
   ],
   "source": [
    "filename = 'cow.jpg' # change to your filename\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "ort_output = run_sample(session_fp32, 'cow.jpg', categories, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f3928b-b10c-4adb-8751-3e0aadb542d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seashore 0.16626585\n",
      "sandbar 0.07883649\n",
      "cliff 0.05631558\n",
      "promontory 0.045474194\n",
      "wreck 0.0038898492\n"
     ]
    }
   ],
   "source": [
    "filename = 'beach.jpg' # change to your filename\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "ort_output = run_sample(session_fp32, 'beach.jpg', categories, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d4cfa1-c785-4254-87c4-8074ba079b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fountain 0.1369517\n",
      "groom 0.09056474\n",
      "castle 0.050991643\n",
      "megalith 0.050879553\n",
      "obelisk 0.029491441\n"
     ]
    }
   ],
   "source": [
    "filename = 'forest.jpg' # change to your filename\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "ort_output = run_sample(session_fp32, 'forest.jpg', categories, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3d4aeb8-7319-424e-8030-561c9ea7e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibus 0.44485015\n",
      "minivan 0.12285038\n",
      "beach wagon 0.026604818\n",
      "jeep 0.019635964\n",
      "recreational vehicle 0.005178272\n"
     ]
    }
   ],
   "source": [
    "filename = 'van.jpg' # change to your filename\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "ort_output = run_sample(session_fp32, 'van.jpg', categories, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88aadf23-1525-40b1-8964-adf6a6c111bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle-built-for-two 0.05923265\n",
      "breakwater 0.057861704\n",
      "unicycle 0.045096885\n",
      "suspension bridge 0.043396775\n",
      "streetcar 0.011755088\n"
     ]
    }
   ],
   "source": [
    "filename = 'road.jpg' # change to your filename\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "ort_output = run_sample(session_fp32, 'road.jpg', categories, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cf46c47-ad04-46d5-8f96-7c4aba75602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook 0.4925105\n",
      "laptop 0.21586348\n",
      "suit 0.011487333\n",
      "marimba 0.00931215\n",
      "projector 0.006159393\n"
     ]
    }
   ],
   "source": [
    "filename = '2persons.jpg' # change to your filename\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "ort_output = run_sample(session_fp32, '2persons.jpg', categories, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f687184-f666-4b94-9ade-a3b4fc691094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "park bench 0.102493845\n",
      "Labrador retriever 0.035666596\n",
      "overskirt 0.015675696\n",
      "Leonberg 0.011895797\n",
      "cloak 0.01167709\n"
     ]
    }
   ],
   "source": [
    "filename = 'woman.jpg' # change to your filename\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "ort_output = run_sample(session_fp32, 'woman.jpg', categories, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26083b5a-747a-460d-b6a1-e22beba3040a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
