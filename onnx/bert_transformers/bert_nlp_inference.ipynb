{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af0c2ad-5e28-4cda-9755-02d0e59110b6",
   "metadata": {},
   "source": [
    "# Load the model in python and transform to onnx\n",
    "\n",
    "### https://onnxruntime.ai/docs/tutorials/csharp/bert-nlp-csharp-console-app.html\n",
    "\n",
    "##### opset_version compatibility\n",
    "\n",
    "https://onnxruntime.ai/docs/reference/compatibility.html#:~:text=ONNX%20Runtime%20supports%20all%20opsets%20from%20the%20latest,with%20ONNX%20opset%20versions%20in%20the%20range%20%5B7-9%5D.\n",
    "\n",
    "- install onnx , torch, transformers\n",
    "\n",
    "### TORCH\n",
    "https://pytorch.org/tutorials//beginner/onnx/export_simple_model_to_onnx_tutorial.html\n",
    "\n",
    "###  Class c# to work with BERTTokenizer Models\n",
    "\n",
    "https://github.com/NMZivkovic/BertTokenizers\n",
    "\n",
    "# Model\n",
    "- bert-large-uncased-whole-word-masking-finetuned-squad\n",
    "\n",
    "### Suported models\n",
    "\n",
    "\n",
    "- BERT Base\n",
    "- BERT Large\n",
    "- BERT German\n",
    "- BERT Multilingual\n",
    "- BERT Base Uncased\n",
    "- BERT Large Uncased\n",
    "\n",
    "# Netron\n",
    "https://github.com/lutzroeder/netron/releases/latest?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2bd660d-5d63-4149-b55f-332cf8964894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "model_path = \"./models/\" + model_name + \"-17b.onnx\"\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81ceaf49-f9d2-44bd-b4df-5fe13c3bdcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53013ae3-4133-4ec1-9c91-a7c0443e9808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cpu'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d89ec0a-dcc1-4ed1-bab9-538326c5325a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fe6e000-f75a-42bd-8dff-bd462b876df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09116742-bdb5-487b-a928-b94127fc4485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.16.1'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adcf5b11-9ad1-4459-b119-8d2ba317ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy inputs to the model. Adjust if neccessary.\n",
    "inputs = {\n",
    "        # list of numerical ids for the tokenized text\n",
    "        'input_ids':   torch.randint(32, [1, 32], dtype=torch.long), \n",
    "        # dummy list of ones\n",
    "        'attention_mask': torch.ones([1, 32], dtype=torch.long),     \n",
    "        # dummy list of ones\n",
    "        'token_type_ids':  torch.ones([1, 32], dtype=torch.long)     \n",
    "    }\n",
    "\n",
    "symbolic_names = {0: 'batch_size', 1: 'max_seq_len'}\n",
    "torch.onnx.export(model,                                         \n",
    "# model being run\n",
    "                  (inputs['input_ids'],\n",
    "                   inputs['attention_mask'], \n",
    "                   inputs['token_type_ids']),                    # model input (or a tuple for multiple inputs)\n",
    "                  model_path,                                    # where to save the model (can be a file or file-like object)\n",
    "                  opset_version=17,  # the ONNX version to export the model to MAX 17\n",
    "                  verbose= True ,\n",
    "                  do_constant_folding=True,                      # whether to execute constant folding for optimization\n",
    "                  input_names=['input_ids',\n",
    "                               'input_mask', \n",
    "                               'segment_ids'],                   # the model's input names\n",
    "                  output_names=['start_logits', \"end_logits\"],   # the model's output names\n",
    "                  dynamic_axes={'input_ids': symbolic_names,\n",
    "                                'input_mask' : symbolic_names,\n",
    "                                'segment_ids' : symbolic_names,\n",
    "                                'start_logits' : symbolic_names, \n",
    "                                'end_logits': symbolic_names})   # variable length axes/dynamic input By default the exported model will have the shapes of all input and output tensors\n",
    "                                                                 #set to exactly match those given in ``args``. To specify axes of tensors as\n",
    "                                                                # dynamic (i.e. known only at run-time), set ``dynamic_axes`` to a dict with schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc81be-2fda-492e-b6b0-fc1f7fc4a871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gguf",
   "language": "python",
   "name": "gguf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
