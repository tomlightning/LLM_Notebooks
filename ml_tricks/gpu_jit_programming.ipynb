{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqJm/tZEIwoy/BsxhfiPWQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olonok69/LLM_Notebooks/blob/main/ml_tricks/gpu_jit_programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cupy\n",
        " CuPy is a NumPy/SciPy-compatible array library for GPU-accelerated computing with Python. CuPy acts as a drop-in replacement to run existing NumPy/SciPy code on NVIDIA CUDA or AMD ROCm platforms.\n",
        "\n",
        "https://pypi.org/project/cupy/\n",
        "\n",
        "https://docs.cupy.dev/en/stable/\n",
        "\n",
        "https://docs.cupy.dev/en/stable/user_guide/basic.html\n",
        "\n",
        "\n",
        "\n",
        "# Numba\n",
        "Numba is an open source, NumPy-aware optimizing compiler for Python sponsored by Anaconda, Inc. It uses the LLVM compiler project to generate machine code from Python syntax.\n",
        "\n",
        " it analyses Python code, turns it into an LLVM IR (intermediate representation), then creates bytecode for the selected architecture (by default, the architecture the host Python runtime is running on). This allows additional enhancements, such as parallelisation and compiling for CUDA as well––given the near-ubiquitous support for LLVM, code can be generated to run on a fairly wide range of architectures (x86, x86_64, PPC, ARMv7, ARMv8) and a number of OSs (Windows, OS X, Linux), as well as on CUDA and AMD’s equivalent, ROC.\n",
        "\n",
        "https://github.com/numba/numba\n"
      ],
      "metadata": {
        "id": "eMa5MY7HxwKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install\n",
        "conda create -n gpu-prog python=3.11 pip\n",
        "\n",
        "pip install cupy-cuda12x numba"
      ],
      "metadata": {
        "id": "-rnjisQa-UxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "mV7Obd36-zv5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs_xu24k-P5Q",
        "outputId": "ec63e794-bb7f-4c1b-ea5b-f159c8761fed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar  3 10:02:32 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA5DxTO2wFXo",
        "outputId": "baf0f297-c408-4a9c-f3f6-d60cc47942ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time execution in CPU = 0.551503 seconds\n",
            "GPU Time 0.023199 seconds\n",
            "GPU is  23.773156 faster\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "from cupyx.profiler import benchmark\n",
        "import cupy as cp\n",
        "from numba import jit\n",
        "\n",
        "t1 = datetime.datetime.now()\n",
        "size = 4096 * 4096\n",
        "input = np.random.random(size).astype(np.float64)\n",
        "# sort the array\n",
        "input= np.sort(input)\n",
        "t2 = datetime.datetime.now()\n",
        "extime = t2 - t1\n",
        "extime = extime.total_seconds()\n",
        "print(f\"time execution in CPU = {extime:.6f} seconds\")\n",
        "\n",
        "# create a cupy array\n",
        "input_gpu = cp.asarray(input)\n",
        "# execute 1 time. overload to copy vector to GPU\n",
        "execution_gpu = benchmark(cp.sort, (input_gpu,), n_repeat=1)\n",
        "gpu_avg_time = np.average(execution_gpu.gpu_times)\n",
        "\n",
        "print(f\"GPU Time {gpu_avg_time:.6f} seconds\")\n",
        "print(f\"GPU is  {(extime/gpu_avg_time):.6f} faster\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sum2d(arr):\n",
        "    M, N = arr.shape\n",
        "    result = 0.0\n",
        "    for i in range(M):\n",
        "        for j in range(N):\n",
        "            result += arr[i,j]\n",
        "    return result"
      ],
      "metadata": {
        "id": "QzXllXNhyjKl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.random.random((10000,10000)).astype(np.float64)\n",
        "t1 = datetime.datetime.now()\n",
        "sum2d(test)\n",
        "t2 = datetime.datetime.now()\n",
        "extime = t2 - t1\n",
        "extime1 = extime.total_seconds()\n",
        "print(f\"time execution in CPU = {extime1:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ozFeazlyp88",
        "outputId": "92e1789b-8056-4cbe-f82f-9616fef3ee7b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time execution in CPU = 24.947120 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numba has two compilation modes: nopython mode and object mode. The former produces much faster code, but has limitations that can force Numba to fall back to the latter. To prevent Numba from falling back, and instead raise an error, pass nopython=True"
      ],
      "metadata": {
        "id": "q68BTxFvkY16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True)\n",
        "def sum2dj(arr):\n",
        "    M, N = arr.shape\n",
        "    result = 0.0\n",
        "    for i in range(M):\n",
        "        for j in range(N):\n",
        "            result += arr[i,j]\n",
        "    return result"
      ],
      "metadata": {
        "id": "IyqygDjQzHTt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.random.random((10000,10000)).astype(np.float64)\n",
        "t1 = datetime.datetime.now()\n",
        "sum2dj(test)\n",
        "t2 = datetime.datetime.now()\n",
        "extime = t2 - t1\n",
        "extime2 = extime.total_seconds()\n",
        "print(f\"time execution in JiT = {extime2:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDae0_jP0fVB",
        "outputId": "8658f698-ec38-478c-832b-a8cf3446698e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time execution in JiT = 0.702635 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"JiT is  {(extime1/extime2):.6f} faster\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOFg_fnc_mXy",
        "outputId": "5a168804-567f-4e26-f0a7-a6631a9c60be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JiT is  35.505092 faster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First execution we need to compile the code and move the function to the GPU"
      ],
      "metadata": {
        "id": "t6VBOMvEKQ2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "\n",
        "@cuda.jit(cache=True)\n",
        "def sum2dc(arr, res):\n",
        "    M, N = arr.shape\n",
        "    for i in range(M):\n",
        "        for j in range(N):\n",
        "            res[0] += arr[i,j]\n",
        ""
      ],
      "metadata": {
        "id": "jwryXbYIAKvR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.random.random((10000,10000)).astype(np.float32)\n",
        "t1 = datetime.datetime.now()\n",
        "res = np.zeros((1), np.float32)\n",
        "sum2dc[1,1](test, res)\n",
        "t2 = datetime.datetime.now()\n",
        "extime = t2 - t1\n",
        "extime3 = extime.total_seconds()\n",
        "print(f\"time execution in GPU = {extime3:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN7zsZdmAd5q",
        "outputId": "7eb070ff-a084-49cc-9f34-b1ec7a3c0eba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time execution in GPU = 6.720016 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRjcGZl8BoBI",
        "outputId": "f3317f4b-f4a1-43ca-f574-ef5ac5b3c9b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16777216.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"cuda is  {(extime1/extime3):.6f} faster\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkZ5coh_Kxeo",
        "outputId": "99de5279-f1a9-44b2-afb5-283ca573dae6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is  3.712360 faster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Second call the function it is already compiled so it will run faster (Compilation overhead)"
      ],
      "metadata": {
        "id": "bLqlt-VhKdB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.random.random((10000,10000)).astype(np.float32)\n",
        "t1 = datetime.datetime.now()\n",
        "res = np.zeros((1), np.float32)\n",
        "sum2dc[1,1](test, res)\n",
        "t2 = datetime.datetime.now()\n",
        "extime = t2 - t1\n",
        "extime3 = extime.total_seconds()\n",
        "print(f\"time execution in GPU = {extime3:.6f} seconds\")\n",
        "print(f\"cuda is  {(extime1/extime3):.6f} faster\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHPKTikgKCW5",
        "outputId": "73125362-0e6c-4c85-a8c0-0865904c3caf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time execution in GPU = 6.539455 seconds\n",
            "cuda is  3.814862 faster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### If we execute the function 100 time as the function it is already compiled and after the first execution already in the GPU, the 99 next executions are done in the GPU, so the process it is faster"
      ],
      "metadata": {
        "id": "UEMAExqmKt9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 10 -r 1 sum2dc[1,1](test, res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WncNtHYhFBWV",
        "outputId": "8d3e5d3b-2503-42ff-ac34-2187f725cbac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.43 s ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extime4 = 6.43"
      ],
      "metadata": {
        "id": "J_oLXtakFVPr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"cuda is  {(extime1/extime4):.6f} faster\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCV5wnYdFRHv",
        "outputId": "c9fa15cc-edb8-4f2a-e0a8-d597fbebe401"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is  3.879801 faster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1-GWZqCRYE6",
        "outputId": "2c6e5542-ab36-4c77-ecf8-0a6319ce084a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49996884.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create a cupy array\n",
        "input_gpu = cp.asarray(test)\n",
        "# execute 1 time. overload to copy vector to GPU\n",
        "execution_gpu = benchmark(cp.sum, (input_gpu,), n_repeat=1)\n",
        "gpu_avg_time_1 = np.average(execution_gpu.gpu_times)\n",
        "\n",
        "print(f\"GPU Time {gpu_avg_time_1:.6f} seconds\")\n",
        "print(f\"GPU is  {(extime1/gpu_avg_time_1):.6f} faster\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYKcKzFjRfDa",
        "outputId": "66261b48-42da-4e2a-9649-ec178e2dc080"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Time 0.001561 seconds\n",
            "GPU is  15985.841514 faster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5mr6fZToR3Pj"
      }
    }
  ]
}