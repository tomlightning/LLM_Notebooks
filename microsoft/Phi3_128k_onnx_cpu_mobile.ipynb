{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1dSfvVkBJDBom9BGrEOyScVMaWGqbyA3r",
      "authorship_tag": "ABX9TyPC9+p8cirNYC6jk3i7ZEWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olonok69/LLM_Notebooks/blob/main/microsoft/Phi3_128k_onnx_cpu_mobile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phi3\n",
        "https://github.com/microsoft/Phi-3CookBook\n",
        "\n",
        "https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-onnx\n",
        "https://techcommunity.microsoft.com/t5/microsoft-developer-community/getting-started-generative-ai-with-phi-3-mini-a-guide-to/ba-p/4121315\n",
        "\n",
        "# ONNX\n",
        "ONNX Runtime is a cross-platform machine-learning model accelerator, with a flexible interface to integrate hardware-specific libraries. ONNX Runtime can be used with models from PyTorch, Tensorflow/Keras, TFLite, scikit-learn, and other frameworks.\n",
        "\n",
        "https://github.com/onnx/onnxmltools\n",
        "###GPU\n",
        "Only CUda 11.8\n",
        "\n",
        "https://onnxruntime.ai/docs/genai/tutorials/phi3-python.html#run-with-nvidia-cuda\n",
        "\n",
        "### Install\n",
        "pip install huggingface-hub hf_transfer --quiet\n",
        "\n",
        "huggingface-cli download microsoft/Phi-3-mini-4k-instruct-onnx --include cuda/cuda-int4-rtn-block-32/* --local-dir .\n",
        "\n",
        "\n",
        "pip install numpy\n",
        "pip install --pre onnxruntime-genai-cuda --index-url=https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-genai/pypi/simple/\n",
        "\n",
        "\n",
        "###CPU\n",
        "https://onnxruntime.ai/docs/genai/tutorials/phi3-python.html#run-on-cpu\n",
        "\n",
        "### Install\n",
        "pip install huggingface-hub hf_transfer --quiet\n",
        "\n",
        "huggingface-cli download microsoft/Phi-3-mini-4k-instruct-onnx --include cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/* --local-dir .\n",
        "\n",
        "pip install numpy\n",
        "pip install --pre onnxruntime-genai\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dlHI3Da-5V09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYc50Wqjr1uN",
        "outputId": "869be972-5b8b-4b0a-87d2-d4cd41de7b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/4.4 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/4.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m3.4/4.4 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install huggingface-hub hf_transfer --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! huggingface-cli download professorf/phi-3-mini-128k-f16-gguf phi-3-mini-128k-f16.gguf --local-dir /content/drive/MyDrive/models/phi3 --local-dir-use-symlinks False\n",
        "#! huggingface-cli download microsoft/Phi-3-mini-4k-instruct-onnx --include cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/* --local-dir /content/drive/MyDrive/models/phi3/onnx\n",
        "#!huggingface-cli download microsoft/Phi-3-mini-128k-instruct-onnx --include cuda/cuda-int4-rtn-block-32/* --local-dir /content/drive/MyDrive/models/phi3/onnx/128k\n",
        "! huggingface-cli download microsoft/Phi-3-mini-4k-instruct-onnx --include cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/* --local-dir /content/drive/MyDrive/models/phi3/cpu/128k\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKyPyZtAsQEY",
        "outputId": "448cd657-6a76-4078-8a63-731cae598b79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching 10 files: 100% 10/10 [00:04<00:00,  2.41it/s]\n",
            "/content/drive/MyDrive/models/phi3/cpu/128k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install --pre onnxruntime-genai\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgtyZevg4Axx",
        "outputId": "88af32d6-904b-4c10-afac-3236390a68bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting onnxruntime-genai\n",
            "  Downloading onnxruntime_genai-0.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxruntime-genai\n",
            "Successfully installed onnxruntime-genai-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime_genai as og\n",
        "import argparse\n",
        "import time"
      ],
      "metadata": {
        "id": "vsenULj6tbxY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = og.Model('/content/drive/MyDrive/models/phi3/cpu/128k/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4')\n",
        "tokenizer = og.Tokenizer(model)\n",
        "tokenizer_stream = tokenizer.create_stream()"
      ],
      "metadata": {
        "id": "GrinoLSuu0Pj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Crossrail link 'to get go-ahead' The £10bn Crossrail transport plan, backed by business groups, is to get the go-ahead this month, according to The Mail on Sunday.\n",
        "It says the UK Treasury has allocated £7.5bn ($13.99bn) for the project and that talks with business groups on raising the rest will begin shortly.\n",
        "The much delayed Crossrail Link Bill would provide for a fast cross-London rail link. The paper says it will go before the House of Commons on 23 February.\n",
        "A second reading could follow on 16 or 17 March. We've always said we are going to introduce a hybrid Bill for Crossrail in the Spring and this remains the case,\n",
        "the Department for Transport said on Sunday. Jeremy de Souza, a spokesman for Crossrail, said on Sunday he could not confirm whether the Treasury was planning to invest £7.5bn\n",
        "or when the bill would go before Parliament. However, he said some impetus may have been provided by the proximity of an election.\n",
        "The new line would go out as far as Maidenhead, Berkshire, to the west of London, and link Heathrow to Canary Wharf via the City.\n",
        "Heathrow to the City would take 40 minutes, dramatically cutting journey times for business travellers, and reducing overcrowding on the tube.\n",
        "The line has the support of the Mayor of London, Ken Livingstone, business groups and the government, but there have been three years of arguments over how it should be funded.\n",
        "The Mail on Sunday's Financial Mail said the £7.5bn of Treasury money was earmarked for spending in £2.5bn instalments in 2010, 2011 and 2012.\"\"\"\n",
        "\n",
        "text2 = \"\"\"           Celeste Barrios-Cruz\n",
        "(312) 208-6505 | Celestebarrios35@gmail.com | LinkedIn | GitHub | Chicago, IL\n",
        "\n",
        "PROFESSIONAL SUMMARY\n",
        "●\n",
        "Innovative thinker with extensive knowledge of SQL, experience utilizing Python, object oriented\n",
        "programming: C++, front end knowledge of JavaScript\n",
        "●\n",
        "Excellent communication skills (English and Spanish) including teamwork and collaboration\n",
        "●\n",
        "Outstanding organization ability including problem-solving, and time management skills.\n",
        "\n",
        "SKILLS\n",
        "Programming Language: Python, C++, JavaScript, HTML5, CSS3, TypeScript\n",
        "Web Technologies/Development Frameworks: NumPy, Pandas, MATLAB, Flask, jQuery, AJAX, JASON,\n",
        "BootstrapUI, Angular7.0\n",
        "Database: SQL, PostgreSQL, SQLite\n",
        "Software: Microsoft Office (Word, Excel, PowerPoint), Google Developer Tools\n",
        "Tools/Methodologies: Data Structures, Algorithms, GitHub, GIT, Heroku, Scrum, Agile Methodology, Agile\n",
        "Software Development, Project Management, Anaconda, Jupyter Notebook, Visual Studio, Software Development,\n",
        "Data Modeler, Tableau\n",
        "Languages: Spanish (fluent conversational skills)\n",
        "\n",
        "EDUCATION\n",
        "University of Illinois at Chicago (UIC), Chicago, IL\n",
        "Bachelor of Science in Math & Computer Science                                               December 2019\n",
        "\n",
        "PROFESSIONAL EXPERIENCE\n",
        "Empower Saturday School, Chicago IL\n",
        "\n",
        "\n",
        "Co-Director of Technology\n",
        "\n",
        "          November 2020-Present\n",
        "●\n",
        "Volunteer in a Non-Profit foundation to provide tutoring for underprivileged youth in Chicago implementing\n",
        "WordPress for a student portal and website with upcoming donation features built-in.\n",
        "\n",
        "Coding Temple, Chicago IL\n",
        "Software Engineer                                                                                               May 2020-July 2020\n",
        "●\n",
        "Participated in intensive professional development experience in code production.\n",
        "●\n",
        "Collaborated with a team to utilize Flask to revamp a law firm’s website from a previous HTML/CSS draft\n",
        "and then deployed the new website on Heroku from GitHub.\n",
        "●\n",
        "Created an Entity Relationship Diagram (ERD) using lucidchart.com to create a database; also used SQL\n",
        "to export and import data between different data sources.\n",
        "●\n",
        "Utilized Object-Oriented Programming (OOP) concepts with Python to create a parking garage system.\n",
        "●\n",
        "Oversaw Full Web UI Development on 5+ projects using Angular 4 and above, AngularJS, JavaScript,\n",
        "HTML, CSS, third party Angular frameworks, JQuery and JSON.\n",
        "●\n",
        "Used 5+ Python libraries and SQL queries/subqueries to create several datasets which produced statistics,\n",
        "tables, figures, charts and graphs.\n",
        "●\n",
        "Completed case study problem sets using Python, NumPy, SciPy, Pandas packages in order to enhance\n",
        "understanding of the functionality of each program and how to get concrete results.\n",
        "\n",
        "PROJECTS\n",
        "Avengers Phone Book\n",
        "\n",
        "\n",
        "●\n",
        "Created phone numbers for Avengers Phone Book using Flask and displayed them to your front page.\n",
        "●\n",
        "Designed a project so that characters could create,read, update their phone number from the phone book;\n",
        "the project is hosted on Heroku.\n",
        "Good Send\n",
        "\n",
        "\n",
        "\n",
        "●\n",
        "Collaborated with 2+ developers to design both administrator and client web portals using Python, Flask,\n",
        "SQLite and multiple APIs; Utilized Github for version control and deployed the final product on Heroku.\n",
        "●\n",
        "Individually designed and deployed a SQLite database to allow organization to run a more secure,\n",
        "organized, automated and efficient operation resulting in higher client satisfaction.\n",
        "●\n",
        "Incorporated Flask-Admin and Flask-Login to allow the administrator to view, create, update and delete.\n",
        "MyMoviePoster\n",
        "\n",
        "●\n",
        "Linked Spotify playlist to movie poster using an API.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "classes = [\"cv\", \"non-cv\"]\n"
      ],
      "metadata": {
        "id": "z_642CS7vJQN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 =  f\"\"\"you are an expert document classifier\n",
        "Classify the following text using these {len(classes)} classes: {classes}\n",
        "Only use the labels provided: {classes}\n",
        "\n",
        "Confidence score: float of 0-1.\n",
        "for example:\n",
        "0 means you are completely sure that the document does not belongs to class x\n",
        "1 means you are completely sure that the document belong to class x\n",
        "output: only respond with a json with these 2 attrubutes 'label' = class predicted, 'score': float\n",
        "\n",
        "#begin text\n",
        "{text2}.\n",
        "#end text\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2QTqBZn_vKnO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the max length to something sensible by default,\n",
        "# since otherwise it will be set to the entire context length\n",
        "search_options = {}\n",
        "search_options['max_length'] = 2048\n",
        "search_options['temperature'] = .7\n",
        "\n",
        "chat_template = '<|user|>\\n{input} <|end|>\\n<|assistant|>'\n",
        "\n",
        "# text = input(\"Input: \")\n",
        "# if not text:\n",
        "#    print(\"Error, input cannot be empty\")\n",
        "#    exit\n",
        "\n",
        "prompt = f'{chat_template.format(input=prompt_1)}'\n",
        "\n"
      ],
      "metadata": {
        "id": "1pnozF1cw5E-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import datetime"
      ],
      "metadata": {
        "id": "DsAYtK1Ue3TN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = tokenizer.encode(prompt)\n",
        "\n",
        "params = og.GeneratorParams(model)\n",
        "params.set_search_options(**search_options)\n",
        "params.input_ids = input_tokens\n",
        "generator = og.Generator(model, params)\n",
        "print(\"Output: \", end='', flush=True)\n",
        "\n",
        "time1=  datetime.datetime.now()\n",
        "try:\n",
        "   while not generator.is_done():\n",
        "     generator.compute_logits()\n",
        "     generator.generate_next_token()\n",
        "\n",
        "     new_token = generator.get_next_tokens()[0]\n",
        "     print(tokenizer_stream.decode(new_token), end='', flush=True)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"  --control+c pressed, aborting generation--\")\n",
        "\n",
        "print()\n",
        "time2=  datetime.datetime.now()\n",
        "print(time2-time1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSx0ZK9tvVTO",
        "outputId": "cabbceaf-7c36-4a74-db6a-083776d91eb2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:  ```json\n",
            "{\n",
            "  \"label\": \"cv\",\n",
            "  \"score\": 0.95\n",
            "}\n",
            "```\n",
            "0:00:38.534175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 =  f\"\"\"you are an expert document classifier\n",
        "Classify the following text using these {len(classes)} classes: {classes}\n",
        "Only use the labels provided: {classes}\n",
        "\n",
        "Confidence score: float of 0-1.\n",
        "for example:\n",
        "0 means you are completely sure that the document does not belongs to class x\n",
        "1 means you are completely sure that the document belong to class x\n",
        "output: only respond with a json with these 2 attrubutes 'label' = class predicted, 'score': float\n",
        "\n",
        "#begin text\n",
        "{text}.\n",
        "#end text\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Db-ulJnpvcOO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the max length to something sensible by default,\n",
        "# since otherwise it will be set to the entire context length\n",
        "search_options = {}\n",
        "search_options['max_length'] = 2048\n",
        "search_options['temperature'] = .7\n",
        "\n",
        "chat_template = '<|user|>\\n{input} <|end|>\\n<|assistant|>'\n",
        "\n",
        "# text = input(\"Input: \")\n",
        "# if not text:\n",
        "#    print(\"Error, input cannot be empty\")\n",
        "#    exit\n",
        "\n",
        "\n",
        "\n",
        "prompt2 = f'{chat_template.format(input=prompt_2)}'"
      ],
      "metadata": {
        "id": "JGEXWcwXvwuN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = tokenizer.encode(prompt2)\n",
        "\n",
        "params = og.GeneratorParams(model)\n",
        "params.set_search_options(**search_options)\n",
        "params.input_ids = input_tokens\n",
        "generator = og.Generator(model, params)\n",
        "print(\"Output: \", end='', flush=True)\n",
        "\n",
        "time1=  datetime.datetime.now()\n",
        "try:\n",
        "   while not generator.is_done():\n",
        "     generator.compute_logits()\n",
        "     generator.generate_next_token()\n",
        "\n",
        "     new_token = generator.get_next_tokens()[0]\n",
        "     print(tokenizer_stream.decode(new_token), end='', flush=True)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"  --control+c pressed, aborting generation--\")\n",
        "\n",
        "print()\n",
        "time2=  datetime.datetime.now()\n",
        "print(time2-time1)"
      ],
      "metadata": {
        "id": "sEE1dutwxlws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5180f4aa-d343-4ccd-dcac-d4c7a323b895"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: {\n",
            " \"label\": \"non-cv\",\n",
            " \"score\": 0.95\n",
            "}\n",
            "\n",
            "{\n",
            " \"label\": \"non-cv\",\n",
            " \"score\": 0.95\n",
            "}\n",
            "\n",
            "{\n",
            " \"label\": \"non-cv\",\n",
            " \"  --control+c pressed, aborting generation--\n",
            "\n",
            "0:00:23.331337\n"
          ]
        }
      ]
    }
  ]
}