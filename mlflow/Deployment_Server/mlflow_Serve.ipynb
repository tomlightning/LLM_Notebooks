{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0f21d2-3abd-4d75-bf0c-8d0b07293709",
   "metadata": {},
   "source": [
    "# Mlflow Deployments\n",
    "\n",
    "https://mlflow.org/docs/latest/llms/deployments/index.html#deployments-rest-api\n",
    "\n",
    "The MLflow Deployments Server is a powerful tool designed to streamline the usage and management of various large language model (LLM) providers, such as OpenAI and Anthropic, within an organization. It offers a high-level interface that simplifies the interaction with these services by providing a unified endpoint to handle specific LLM related requests.\n",
    "\n",
    "A major advantage of using the MLflow Deployments Server is its centralized management of API keys. By storing these keys in one secure location, organizations can significantly enhance their security posture by minimizing the exposure of sensitive API keys throughout the system. It also helps to prevent exposing these keys within code or requiring end-users to manage keys safely.\n",
    "\n",
    "The deployments server is designed to be flexible and adaptable, capable of easily defining and managing endpoints by updating the configuration file. This enables the easy incorporation of new LLM providers or provider LLM types into the system without necessitating changes to applications that interface with the deployments server. This level of adaptability makes the MLflow Deployments Server Service an invaluable tool in environments that require agility and quick response to changes.\n",
    "\n",
    "## EndPoint Configuration File\n",
    "\n",
    "```python\n",
    "endpoints:\n",
    "  - name: completions\n",
    "    endpoint_type: llm/v1/completions\n",
    "    model:\n",
    "      provider: openai\n",
    "      name: gpt-3.5-turbo\n",
    "      config:\n",
    "        openai_api_key: $OPENAI_API_KEY\n",
    "    limit:\n",
    "      renewal_period: minute\n",
    "      calls: 10\n",
    "\n",
    "  - name: chat\n",
    "    endpoint_type: llm/v1/chat\n",
    "    model:\n",
    "      provider: openai\n",
    "      name: gpt-3.5-turbo\n",
    "      config:\n",
    "        openai_api_key: $OPENAI_API_KEY\n",
    "\n",
    "  - name: chat-gpt4\n",
    "    endpoint_type: llm/v1/chat\n",
    "    model:\n",
    "      provider: openai\n",
    "      name: gpt-4\n",
    "      config:\n",
    "        openai_api_key: $OPENAI_API_KEY\n",
    "\n",
    "  - name: embeddings\n",
    "    endpoint_type: llm/v1/embeddings\n",
    "    model:\n",
    "      provider: openai\n",
    "      name: text-embedding-ada-002\n",
    "      config:\n",
    "        openai_api_key: $OPENAI_API_KEY\n",
    "\n",
    "  - name: antrophic-chat\n",
    "    endpoint_type: llm/v1/chat\n",
    "    model:\n",
    "      provider: anthropic\n",
    "      name: claude-2.1\n",
    "      config:\n",
    "        anthropic_api_key: $ANTHROPIC_API_KEY\n",
    "```\n",
    "\n",
    "# Install\n",
    "\n",
    "pip install 'mlflow[genai]'\n",
    "\n",
    "\n",
    "- export OPENAI_API_KEY\n",
    "- export MLFLOW_DEPLOYMENTS_CONFIG \n",
    "- export MLFLOW_DEPLOYMENTS_TARGET \n",
    "- export ANTHROPIC_API_KEY\n",
    "\n",
    "mlflow deployments start-server --config-path /mnt/d/repos/mlserve/config.yaml --port 5888 --host 0.0.0.0 --workers 2 &\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f1c10f-93ec-4184-8304-05f90a2261b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olonok/.local/lib/python3.11/site-packages/pydantic/_internal/_config.py:334: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a074fd1-e06b-41f2-b5e7-653a4f221d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7f3c7a-4f43-4617-8140-09c5dfc0748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_deploy_client(\"http://127.0.0.1:5888\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff3a5807-7a60-4839-b59e-a4e655ed2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_points = client.list_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc9d91ad-98a9-4f1c-ab04-ca845fb22554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='completions' endpoint_type='llm/v1/completions' model=RouteModelInfo(name='gpt-3.5-turbo', provider='openai') endpoint_url='http://127.0.0.1:5888/gateway/completions/invocations' limit=Limit(calls=10, key=None, renewal_period='minute')\n",
      "--------------------------------------------------\n",
      "name='chat' endpoint_type='llm/v1/chat' model=RouteModelInfo(name='gpt-3.5-turbo', provider='openai') endpoint_url='http://127.0.0.1:5888/gateway/chat/invocations' limit=None\n",
      "--------------------------------------------------\n",
      "name='chat-gpt4' endpoint_type='llm/v1/chat' model=RouteModelInfo(name='gpt-4', provider='openai') endpoint_url='http://127.0.0.1:5888/gateway/chat-gpt4/invocations' limit=None\n",
      "--------------------------------------------------\n",
      "name='embeddings' endpoint_type='llm/v1/embeddings' model=RouteModelInfo(name='text-embedding-ada-002', provider='openai') endpoint_url='http://127.0.0.1:5888/gateway/embeddings/invocations' limit=None\n",
      "--------------------------------------------------\n",
      "name='antrophic-chat' endpoint_type='llm/v1/chat' model=RouteModelInfo(name='claude-2.1', provider='anthropic') endpoint_url='http://127.0.0.1:5888/gateway/antrophic-chat/invocations' limit=None\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for e in end_points:\n",
    "    print(e)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1741b755-8544-42ab-a3bd-8dc6cd8f9662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9XQp2hj66LcCmK704g0dF3GLIIof8', 'object': 'chat.completion', 'created': 1717754956, 'model': 'gpt-3.5-turbo-0125', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Why did the taxidriver break up with his girlfriend? Because she kept asking for a fare relationship!'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 16, 'completion_tokens': 21, 'total_tokens': 37}}\n"
     ]
    }
   ],
   "source": [
    "response = client.predict(\n",
    "    endpoint=\"chat\",\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about taxidrivers\"}]},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c1dbc68-5982-4a1c-a750-d30d389dcaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'msg_015MK9n6Gmu76DJKMg5ZKje5', 'object': 'chat.completion', 'created': 1717755001, 'model': 'claude-2.1', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Why don't taxidrivers like taking mathematicians as passengers? Because they always ask too many questions about the shortest route!\"}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 30, 'total_tokens': 48}}\n"
     ]
    }
   ],
   "source": [
    "response = client.predict(\n",
    "    endpoint=\"antrophic-chat\",\n",
    "    inputs={\"max_tokens\": 2000, \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about taxidrivers\"}]},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fd81f71-beb0-42cc-99e2-7c7320a583be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9XQpzPLFws905opQKqFnuYxY0vP5j', 'object': 'chat.completion', 'created': 1717755015, 'model': 'gpt-4-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Why don't taxidrivers ever get lost?\\n\\nBecause they always follow their fare instincts!\"}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 16, 'completion_tokens': 19, 'total_tokens': 35}}\n"
     ]
    }
   ],
   "source": [
    "response = client.predict(\n",
    "    endpoint=\"chat-gpt4\",\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about taxidrivers\"}]},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "783c9ed0-5a01-4eff-a96f-e2a06eb3aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    \"prompt\": (\n",
    "        \"What would happen if an asteroid the size of \"\n",
    "        \"a basketball encountered the Earth traveling at 0.5c? \"\n",
    "        \"Please provide your answer in .rst format for the purposes of documentation.\"\n",
    "    ),\n",
    "    \"temperature\": 0.5,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"n\": 1,\n",
    "    \"frequency_penalty\": 0.2,\n",
    "    \"presence_penalty\": 0.2,\n",
    "}\n",
    "\n",
    "r = client.predict(endpoint=\"completions\", inputs=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4330c5b-85af-438d-9cae-d6c26d4b47b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9XQq5lbL5HAYVrs8F1ozzOwY52YY1',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1717755021,\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'choices': [{'index': 0,\n",
       "   'text': \"# Asteroid Impact Scenario\\n\\n## Description\\n\\nAn asteroid the size of a basketball is traveling towards Earth at a velocity of 0.5 times the speed of light (0.5c).\\n\\n## Potential Consequences\\n\\n1. Upon impact, the asteroid would release a massive amount of energy due to its high velocity.\\n2. The impact would result in a significant explosion upon contact with Earth's surface.\\n3. The explosion would generate a shockwave that could cause widespread destruction in the surrounding area.\\n4. The impact crater created by the asteroid would be substantial, potentially causing further damage to the local environment.\\n5. The release of debris and dust into the atmosphere could lead to long-term environmental consequences, such as climate change and decreased sunlight reaching the surface.\\n\\n## Recommendations\\n\\n1. Monitor the trajectory of the asteroid and assess potential impact zones.\\n2. Implement evacuation procedures for areas at risk of being affected by the impact.\\n3. Coordinate with international agencies to develop a response plan for mitigating the effects of the asteroid impact.\\n4. Consider implementing early warning systems to alert populations in advance of potential impact events.\",\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 43, 'completion_tokens': 223, 'total_tokens': 266}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ac135e4-9d89-4e48-9d43-d716174d67d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Asteroid Impact Scenario\n",
      "\n",
      "## Description\n",
      "\n",
      "An asteroid the size of a basketball is traveling towards Earth at a velocity of 0.5 times the speed of light (0.5c).\n",
      "\n",
      "## Potential Consequences\n",
      "\n",
      "1. Upon impact, the asteroid would release a massive amount of energy due to its high velocity.\n",
      "2. The impact would result in a significant explosion upon contact with Earth's surface.\n",
      "3. The explosion would generate a shockwave that could cause widespread destruction in the surrounding area.\n",
      "4. The impact crater created by the asteroid would be substantial, potentially causing further damage to the local environment.\n",
      "5. The release of debris and dust into the atmosphere could lead to long-term environmental consequences, such as climate change and decreased sunlight reaching the surface.\n",
      "\n",
      "## Recommendations\n",
      "\n",
      "1. Monitor the trajectory of the asteroid and assess potential impact zones.\n",
      "2. Implement evacuation procedures for areas at risk of being affected by the impact.\n",
      "3. Coordinate with international agencies to develop a response plan for mitigating the effects of the asteroid impact.\n",
      "4. Consider implementing early warning systems to alert populations in advance of potential impact events.\n"
     ]
    }
   ],
   "source": [
    "print(r['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5cb271f-caaf-450f-b252-7a38fac1d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import Mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da92f30f-c257-48d6-877d-9fabe074b81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/olonok/mlflow/mlruns/21', creation_time=1717748561923, experiment_id='21', last_update_time=1717748561923, lifecycle_stage='active', name='ml_server', tags={}>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"ml_server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d9b5865-8ff6-4be8-94ba-161445722474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two tired!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olonok/anaconda3/envs/mlflow_serve/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/olonok/anaconda3/envs/mlflow_serve/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired.\"]\n"
     ]
    }
   ],
   "source": [
    "llm = Mlflow(target_uri=\"http://127.0.0.1:5888\", endpoint=\"completions\")\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"adjective\"],\n",
    "        template=\"Tell me a {adjective} joke\",\n",
    "    ),\n",
    ")\n",
    "result = llm_chain.run(adjective=\"funny\")\n",
    "print(result)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.langchain.log_model(llm_chain, \"model\")\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "print(model.predict([{\"adjective\": \"very sad\"}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "670354b3-a1fd-45c1-bca6-fed1fe86698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.deployments.set_deployments_target(\"http://127.0.0.1:5888\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca108950-8f43-4d04-82af-6aaf91a8f08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:5888'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.deployments.get_deployments_target() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "941f51a0-091d-4713-b440-673ece32d5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"endpoints\":[{\"name\":\"completions\",\"endpoint_type\":\"llm/v1/completions\",\"model\":{\"name\":\"gpt-3.5-turbo\",\"provider\":\"openai\"},\"endpoint_url\":\"/gateway/completions/invocations\",\"limit\":{\"calls\":10,\"key\":null,\"renewal_period\":\"minute\"}},{\"name\":\"chat\",\"endpoint_type\":\"llm/v1/chat\",\"model\":{\"name\":\"gpt-3.5-turbo\",\"provider\":\"openai\"},\"endpoint_url\":\"/gateway/chat/invocations\",\"limit\":null},{\"name\":\"chat-gpt4\",\"endpoint_type\":\"llm/v1/chat\",\"model\":{\"name\":\"gpt-4\",\"provider\":\"openai\"},\"endpoint_url\":\"/gateway/chat-gpt4/invocations\",\"limit\":null},{\"name\":\"embeddings\",\"endpoint_type\":\"llm/v1/embeddings\",\"model\":{\"name\":\"text-embedding-ada-002\",\"provider\":\"openai\"},\"endpoint_url\":\"/gateway/embeddings/invocations\",\"limit\":null},{\"name\":\"antrophic-chat\",\"endpoint_type\":\"llm/v1/chat\",\"model\":{\"name\":\"claude-2.1\",\"provider\":\"anthropic\"},\"endpoint_url\":\"/gateway/antrophic-chat/invocations\",\"limit\":null}],\"next_page_token\":null}"
     ]
    }
   ],
   "source": [
    "! curl -X GET \"http://0.0.0.0:5888/api/2.0/endpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2bbc46-040c-4d3f-bfcb-044c450cb604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
