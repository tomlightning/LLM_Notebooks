{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bea6c0e8-8e95-474f-92dd-2564f5669ed0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Inspect\n",
    "The inspect module provides several useful functions to help get information about live objects such as modules, classes, methods, functions, tracebacks, frame objects, and code objects. For example, it can help you examine the contents of a class, retrieve the source code of a method, extract and format the argument list for a function, or get all the information you need to display a detailed traceback.\n",
    "\n",
    "There are four main kinds of services provided by this module: type checking, getting source code, inspecting classes and functions, and examining the interpreter stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87a72cfb-8516-45b8-aa12-56d95fb539f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Disable a few less-than-useful UserWarnings from setuptools and pydantic\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac0ed136-c8b9-4857-8ae9-d8f171bc4065",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import inspect\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "import openai\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.types.schema import ColSpec, ParamSchema, ParamSpec, Schema\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e70b624-af17-4cef-8828-70f264f65891",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY= dbutils.secrets.get(scope= \"databricks-azure\", key = \"OPENAIAPIKEY\")\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48955bed-207e-4307-8296-0bef1c4bd4dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert \"OPENAI_API_KEY\" in os.environ, \"Please set the OPENAI_API_KEY environment variable.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "890f7671-a729-4c84-8a68-07dc9bbaa51e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/16 21:04:52 INFO mlflow.tracking.fluent: Experiment with name '/Users/olonok@hotmail.com/Code Helper 2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/2965825698891942', creation_time=1718571893117, experiment_id='2965825698891942', last_update_time=1718571893117, lifecycle_stage='active', name='/Users/olonok@hotmail.com/Code Helper 2', tags={'mlflow.experiment.sourceName': '/Users/olonok@hotmail.com/Code Helper 2',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'olonok@hotmail.com',\n",
       " 'mlflow.ownerId': '1491868126462402'}>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/Users/olonok@hotmail.com/Code Helper 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aea90385-dea4-4288-8e82-0c6964dd42b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "instruction = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"As an AI specializing in code review, your task is to analyze and critique the submitted code. For each code snippet, provide a detailed review that includes: \"\n",
    "            \"1. Identification of any errors or bugs. \"\n",
    "            \"2. Suggestions for optimizing code efficiency and structure. \"\n",
    "            \"3. Recommendations for enhancing code readability and maintainability. \"\n",
    "            \"4. Best practice advice relevant to the codeâ€™s language and functionality. \"\n",
    "            \"Your feedback should help the user improve their coding skills and understand best practices in software development.\"\n",
    "        ),\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Review my code and suggest improvements: {code}\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "359d3657-aa5b-44ed-9986-808c4b0d6587",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cf4cae8aad4d40b103e202786c99a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/16 21:08:14 INFO mlflow.store.artifact.cloud_artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    }
   ],
   "source": [
    "# Define the model signature that will be used for both the base model and the eventual custom pyfunc implementation later.\n",
    "signature = ModelSignature(\n",
    "    inputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "    outputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "    params=ParamSchema(\n",
    "        [\n",
    "            ParamSpec(name=\"max_tokens\", default=500, dtype=\"long\"),\n",
    "            ParamSpec(name=\"temperature\", default=0, dtype=\"float\"),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Log the base OpenAI model with the included instruction set (prompt)\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.openai.log_model(\n",
    "        model=\"gpt-4\",\n",
    "        task=openai.chat.completions,\n",
    "        artifact_path=\"base_model\",\n",
    "        messages=instruction,\n",
    "        signature=signature,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "228d5965-0e88-4488-887c-1d8317bbd22d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'runs:/c64b496d34ba43d4b98944ba44bf21d8/base_model'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3f4ec3c-6069-48c0-9e4f-b0d7e6353044",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom pyfunc implementation that applies text and code formatting to the output results from the OpenAI model\n",
    "class CodeHelper(PythonModel):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.model = mlflow.pyfunc.load_model(context.artifacts[\"model_path\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_response(response):\n",
    "        formatted_output = \"\"\n",
    "        in_code_block = False\n",
    "\n",
    "        for item in response:\n",
    "            lines = item.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                # Check for the start/end of a code block\n",
    "                if line.strip().startswith(\"```\"):\n",
    "                    in_code_block = not in_code_block\n",
    "                    formatted_output += line + \"\\n\"\n",
    "                    continue\n",
    "\n",
    "                if in_code_block:\n",
    "                    # Don't wrap lines inside code blocks\n",
    "                    formatted_output += line + \"\\n\"\n",
    "                else:\n",
    "                    # Wrap lines outside of code blocks\n",
    "                    wrapped_lines = textwrap.fill(line, width=80)\n",
    "                    formatted_output += wrapped_lines + \"\\n\"\n",
    "\n",
    "        return formatted_output\n",
    "\n",
    "    def predict(self, context, model_input, params):\n",
    "        # Call the loaded OpenAI model instance to get the raw response\n",
    "        raw_response = self.model.predict(model_input, params=params)\n",
    "\n",
    "        # Return the formatted response so that it is easier to read\n",
    "        return self._format_response(raw_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7e31a74-a08c-4612-acb4-32153f3f4c32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "210b7981-ff5d-43e1-95d8-aa734d4d9a55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'runs:/c64b496d34ba43d4b98944ba44bf21d8/base_model'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51973053-3f44-4552-aeed-09066afed792",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/16 21:18:08 INFO mlflow.models.utils: Lists of scalar values are not converted to a pandas DataFrame. If you expect to use pandas DataFrames for inference, please construct a DataFrame and pass it to input_example instead.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05081bacb164cfc802982bee24da756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/16 21:18:09 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f44e68e81f0440cb2c3d09b232201e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/16 21:18:29 INFO mlflow.store.artifact.cloud_artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    }
   ],
   "source": [
    "# Define the location of the base model that we'll be using within our custom pyfunc implementation\n",
    "artifacts = {\"model_path\": model_info.model_uri}\n",
    "runname = f'code_helper_{datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")}'\n",
    "with mlflow.start_run(run_name=runname) as run:\n",
    "    helper_model = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"code_helper\",\n",
    "        python_model=CodeHelper(),\n",
    "        input_example=[\"x = 1\"],\n",
    "        signature=signature,\n",
    "        artifacts=artifacts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bad6b33-b111-464b-ba1c-0b9eda6da1e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'runs:/47b84e1d2f074a6b84ff1595368bed3a/code_helper'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper_model.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "261a791e-2c2c-4b7a-a6f8-742ba8728004",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f3cfd3210a4bb18a67c1f0eef5cbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/16 21:20:13 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    }
   ],
   "source": [
    "loaded_helper = mlflow.pyfunc.load_model(helper_model.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a3ed5cd-e00b-4683-8c58-429e34343345",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on PyFuncModel in module mlflow.pyfunc object:\n\nclass PyFuncModel(builtins.object)\n |  PyFuncModel(model_meta: mlflow.models.model.Model, model_impl: Any, predict_fn: str = 'predict')\n |  \n |  MLflow 'python function' model.\n |  \n |  Wrapper around model implementation and metadata. This class is not meant to be constructed\n |  directly. Instead, instances of this class are constructed and returned from\n |  :py:func:`load_model() <mlflow.pyfunc.load_model>`.\n |  \n |  ``model_impl`` can be any Python object that implements the `Pyfunc interface\n |  <https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#pyfunc-inference-api>`_, and is\n |  returned by invoking the model's ``loader_module``.\n |  \n |  ``model_meta`` contains model metadata loaded from the MLmodel file.\n |  \n |  Methods defined here:\n |  \n |  __eq__(self, other)\n |      Return self==value.\n |  \n |  __init__(self, model_meta: mlflow.models.model.Model, model_impl: Any, predict_fn: str = 'predict')\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  predict(self, data: Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, ForwardRef('csc_matrix'), ForwardRef('csr_matrix'), List[Any], Dict[str, Any], datetime.datetime, bool, bytes, float, int, str, pyspark.sql.dataframe.DataFrame], params: Optional[Dict[str, Any]] = None) -> Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list, str, pyspark.sql.dataframe.DataFrame]\n |      Generates model predictions.\n |      \n |      If the model contains signature, enforce the input schema first before calling the model\n |      implementation with the sanitized input. If the pyfunc model does not include model schema,\n |      the input is passed to the model implementation as is. See `Model Signature Enforcement\n |      <https://www.mlflow.org/docs/latest/models.html#signature-enforcement>`_ for more details.\n |      \n |      Args:\n |          data: Model input as one of pandas.DataFrame, numpy.ndarray,\n |              scipy.sparse.(csc_matrix | csr_matrix), List[Any], or\n |              Dict[str, numpy.ndarray].\n |              For model signatures with tensor spec inputs\n |              (e.g. the Tensorflow core / Keras model), the input data type must be one of\n |              `numpy.ndarray`, `List[numpy.ndarray]`, `Dict[str, numpy.ndarray]` or\n |              `pandas.DataFrame`. If data is of `pandas.DataFrame` type and the model\n |              contains a signature with tensor spec inputs, the corresponding column values\n |              in the pandas DataFrame will be reshaped to the required shape with 'C' order\n |              (i.e. read / write the elements using C-like index order), and DataFrame\n |              column values will be cast as the required tensor spec type. For Pyspark\n |              DataFrame inputs, MLflow will only enforce the schema on a subset\n |              of the data rows.\n |          params: Additional parameters to pass to the model for inference.\n |      \n |              .. Note:: Experimental: This parameter may change or be removed in a future\n |                  release without warning.\n |      \n |      Returns:\n |          Model predictions as one of pandas.DataFrame, pandas.Series, numpy.ndarray or list.\n |  \n |  unwrap_python_model(self)\n |      .. Note:: Experimental: This function may change or be removed in a future release without warning.\n |      \n |      \n |      Unwrap the underlying Python model object.\n |      \n |      This method is useful for accessing custom model functions, while still being able to\n |      leverage the MLflow designed workflow through the `predict()` method.\n |      \n |      Returns:\n |          The underlying wrapped model object\n |      \n |      .. code-block:: python\n |          :test:\n |          :caption: Example\n |      \n |          import mlflow\n |      \n |      \n |          # define a custom model\n |          class MyModel(mlflow.pyfunc.PythonModel):\n |              def predict(self, context, model_input, params=None):\n |                  return self.my_custom_function(model_input, params)\n |      \n |              def my_custom_function(self, model_input, params=None):\n |                  # do something with the model input\n |                  return 0\n |      \n |      \n |          some_input = 1\n |          # save the model\n |          with mlflow.start_run():\n |              model_info = mlflow.pyfunc.log_model(artifact_path=\"model\", python_model=MyModel())\n |      \n |          # load the model\n |          loaded_model = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)\n |          print(type(loaded_model))  # <class 'mlflow.pyfunc.model.PyFuncModel'>\n |          unwrapped_model = loaded_model.unwrap_python_model()\n |          print(type(unwrapped_model))  # <class '__main__.MyModel'>\n |      \n |          # does not work, only predict() is exposed\n |          # print(loaded_model.my_custom_function(some_input))\n |          print(unwrapped_model.my_custom_function(some_input))  # works\n |          print(loaded_model.predict(some_input))  # works\n |      \n |          # works, but None is needed for context arg\n |          print(unwrapped_model.predict(None, some_input))\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties defined here:\n |  \n |  loader_module\n |      Model's flavor configuration\n |      \n |      .. Note:: Experimental: This property may change or be removed in a future release without warning.\n |  \n |  metadata\n |      Model metadata.\n |  \n |  model_config\n |      Model's flavor configuration\n |      \n |      .. Note:: Experimental: This property may change or be removed in a future release without warning.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __hash__ = None\n\n"
     ]
    }
   ],
   "source": [
    "help(loaded_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a9290df-e4a5-4e2f-a3db-744662a5cb61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'info': {'artifact_uri': 'dbfs:/databricks/mlflow-tracking/2965825698891942/47b84e1d2f074a6b84ff1595368bed3a/artifacts',\n",
       "  'end_time': None,\n",
       "  'experiment_id': '2965825698891942',\n",
       "  'lifecycle_stage': 'active',\n",
       "  'run_id': '47b84e1d2f074a6b84ff1595368bed3a',\n",
       "  'run_name': 'code_helper_2024-06-16_21:18:07',\n",
       "  'run_uuid': '47b84e1d2f074a6b84ff1595368bed3a',\n",
       "  'start_time': 1718572687755,\n",
       "  'status': 'RUNNING',\n",
       "  'user_id': ''},\n",
       " 'data': {'metrics': {},\n",
       "  'params': {},\n",
       "  'tags': {'mlflow.databricks.cluster.id': '0616-184429-cxigo2mp',\n",
       "   'mlflow.databricks.notebook.commandID': '1718565613149_7315845277717661672_e9139b2a5e2049ec9f52cdfd6e25b1b9',\n",
       "   'mlflow.databricks.notebookID': '1200508474543255',\n",
       "   'mlflow.databricks.notebookPath': '/Users/olonok@hotmail.com/Databricks LLMOps 2',\n",
       "   'mlflow.databricks.webappURL': 'https://ukwest.azuredatabricks.net',\n",
       "   'mlflow.databricks.workspaceID': '1286930193882465',\n",
       "   'mlflow.databricks.workspaceURL': 'adb-1286930193882465.5.azuredatabricks.net',\n",
       "   'mlflow.runName': 'code_helper_2024-06-16_21:18:07',\n",
       "   'mlflow.source.name': '/Users/olonok@hotmail.com/Databricks LLMOps 2',\n",
       "   'mlflow.source.type': 'NOTEBOOK',\n",
       "   'mlflow.user': '1491868126462402'}}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "227ee07d-4446-4419-864a-a033c4c92679",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_helper - olonok@hotmail_com\n"
     ]
    }
   ],
   "source": [
    "# Define the name for the model in the Model Registry.\n",
    "# We filter out some special characters which cannot be used in model names.\n",
    "user= \"olonok@hotmail.com\"\n",
    "model_name = f\"code_helper - {user}\"\n",
    "model_name = model_name.replace(\"/\", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7be54d09-0927-43db-b845-c66cb4d692e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'runs:/47b84e1d2f074a6b84ff1595368bed3a/code_helper'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper_model.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4557f66-0461-4d73-811b-6c1f07718491",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'code_helper - olonok@hotmail_com' already exists. Creating a new version of this model...\n2024/06/16 21:21:32 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: code_helper - olonok@hotmail_com, version 4\nCreated version '4' of model 'code_helper - olonok@hotmail_com'.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1718572892011, current_stage='None', description='', last_updated_timestamp=1718572892011, name='code_helper - olonok@hotmail_com', run_id='47b84e1d2f074a6b84ff1595368bed3a', run_link='', source='dbfs:/databricks/mlflow-tracking/2965825698891942/47b84e1d2f074a6b84ff1595368bed3a/artifacts/code_helper', status='PENDING_REGISTRATION', status_message='', tags={}, user_id='1491868126462402', version='4'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register a new model under the given name, or a new model version if the name exists already.\n",
    "mlflow.register_model(model_uri=helper_model.model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76c34c96-c3f8-4595-9f4b-e054c19b110c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Test the LLM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82c3ce81-d17f-4eb5-9c6a-4c935656ae2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b99b2a7-6f19-4e34-8ec1-62f98b8bd807",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<RegisteredModel: aliases={}, creation_timestamp=1718566410571, description='', last_updated_timestamp=1718572892011, latest_versions=[<ModelVersion: aliases=[], creation_timestamp=1718570009657, current_stage='Archived', description='', last_updated_timestamp=1718570503610, name='code_helper - olonok@hotmail_com', run_id='f060faa5186442e8adebac206d8c7391', run_link='', source='dbfs:/databricks/mlflow-tracking/1200508474543296/f060faa5186442e8adebac206d8c7391/artifacts/base_model', status='READY', status_message='', tags={}, user_id='olonok@hotmail.com', version='2'>,\n",
       "  <ModelVersion: aliases=[], creation_timestamp=1718572892011, current_stage='None', description='', last_updated_timestamp=1718572897211, name='code_helper - olonok@hotmail_com', run_id='47b84e1d2f074a6b84ff1595368bed3a', run_link='', source='dbfs:/databricks/mlflow-tracking/2965825698891942/47b84e1d2f074a6b84ff1595368bed3a/artifacts/code_helper', status='READY', status_message='', tags={}, user_id='olonok@hotmail.com', version='4'>,\n",
       "  <ModelVersion: aliases=[], creation_timestamp=1718570466836, current_stage='Production', description='', last_updated_timestamp=1718570670119, name='code_helper - olonok@hotmail_com', run_id='bf679081e9a04987b0252bbe15e58f5b', run_link='', source='dbfs:/databricks/mlflow-tracking/1200508474543296/bf679081e9a04987b0252bbe15e58f5b/artifacts/code_helper', status='READY', status_message='', tags={}, user_id='olonok@hotmail.com', version='3'>], name='code_helper - olonok@hotmail_com', tags={}>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_registered_models(filter_string=f\"name = '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d0dfbf6-2df1-43d6-b764-1380a16941f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d54c994bd7416685b8eff268ab4b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/16 21:23:51 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: code_helper\n",
       "  flavor: mlflow.pyfunc.model\n",
       "  run_id: bf679081e9a04987b0252bbe15e58f5b"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 3\n",
    "dev_model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "dev_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20a93651-819f-4177-b0d5-614a6c6289da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/1274/command-1200508474543282-3079282698:1: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.11.3/model-registry.html#migrating-from-stages\n  client.transition_model_version_stage(model_name, model_version, \"Archived\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1718570466836, current_stage='Archived', description='', last_updated_timestamp=1718573039000, name='code_helper - olonok@hotmail_com', run_id='bf679081e9a04987b0252bbe15e58f5b', run_link='', source='dbfs:/databricks/mlflow-tracking/1200508474543296/bf679081e9a04987b0252bbe15e58f5b/artifacts/code_helper', status='READY', status_message='', tags={}, user_id='1491868126462402', version='3'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.transition_model_version_stage(model_name, model_version, \"Archived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db8167e9-0acc-45d4-9faf-464b2755565c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d1c919cd9647e49d3d4841f9ff508c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/16 21:24:19 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: code_helper\n",
       "  flavor: mlflow.pyfunc.model\n",
       "  run_id: 47b84e1d2f074a6b84ff1595368bed3a"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 4\n",
    "dev_model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "dev_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e27e81d-f61b-48f1-85c6-d04fe0337ea0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "staging_model = dev_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f287dd9d-1faa-418e-9d2c-488ae4df31f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def review(func, model):\n",
    "    \"\"\"\n",
    "    Function to review the source code of a given function using a specified MLflow model.\n",
    "\n",
    "    Args:\n",
    "    func (function): The function to review.\n",
    "    model (MLflow pyfunc model): The MLflow pyfunc model used for evaluation.\n",
    "\n",
    "    Returns:\n",
    "    The model's prediction or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extracting the source code of the function\n",
    "        source_code = inspect.getsource(func)\n",
    "\n",
    "        # Using the model to predict/evaluate the source code\n",
    "        prediction = model.predict([source_code])\n",
    "        print(prediction)\n",
    "    except Exception as e:\n",
    "        # Handling any exceptions that occur and returning an error message\n",
    "        return f\"Error during model prediction or source code inspection: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4fb1f1e-0806-4f05-b171-6492199545c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a review of your code:\n\n1. Errors or bugs: There are no syntax errors in your code, but the logic seems\nto be flawed. The code is supposed to count the number of duplicate elements in\nthe list and return a list of unique elements sorted in descending order.\nHowever, the way you're checking for duplicates and creating the list of unique\nelements is incorrect and inefficient.\n\n2. Optimizing code efficiency and structure: The current code has a time\ncomplexity of O(n^2) due to the nested for loops and the use of the 'in'\noperator in a list, which is inefficient for large lists. You can use Python's\nbuilt-in data structures like set and Counter from collections module to\noptimize this.\n\n3. Enhancing code readability and maintainability: The variable names are not\ndescriptive, which makes the code hard to understand. Using meaningful variable\nnames can greatly improve code readability.\n\n4. Best practice advice: It's a good practice to add docstrings to your\nfunctions to explain what they do. Also, avoid using single letter variable\nnames.\n\nHere's an optimized version of your code:\n\n```python\nfrom collections import Counter\n\ndef process_data(lst):\n    \"\"\"\n    This function takes a list, counts the number of duplicate elements,\n    and returns a list of unique elements sorted in descending order along with the count of duplicates.\n    \"\"\"\n    element_counts = Counter(lst)\n    unique_elements = list(element_counts.keys())\n    duplicates_count = sum(count - 1 for count in element_counts.values() if count > 1)\n    unique_elements.sort(reverse=True)\n    return unique_elements, duplicates_count\n```\n\nThis version of the code uses the Counter class from the collections module to\ncount the occurrences of each element in the list. It then creates a list of\nunique elements by getting the keys from the Counter object. The count of\nduplicates is calculated by summing up the counts of elements that appear more\nthan once. Finally, the list of unique elements is sorted in descending order.\nThis version of the code is more efficient, readable, and maintainable.\n\n"
     ]
    }
   ],
   "source": [
    "def process_data(lst):\n",
    "    s = 0\n",
    "    q = []\n",
    "    for i in range(len(lst)):\n",
    "        a = lst[i]\n",
    "        for j in range(i + 1, len(lst)):\n",
    "            b = lst[j]\n",
    "            if a == b:\n",
    "                s += 1\n",
    "            else:\n",
    "                q.append(b)\n",
    "    rslt = [x for x in lst if x not in q]\n",
    "    k = []\n",
    "    for i in rslt:\n",
    "        if i not in k:\n",
    "            k.append(i)\n",
    "    final_data = sorted(k, reverse=True)\n",
    "    return final_data, s\n",
    "\n",
    "\n",
    "review(process_data, staging_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "240ecfec-2cda-419c-88ec-6851e58a7d52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/1274/command-1200508474543287-3157488612:1: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.11.3/model-registry.html#migrating-from-stages\n  client.transition_model_version_stage(model_name, model_version, \"production\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1718572892011, current_stage='Production', description='', last_updated_timestamp=1718573378756, name='code_helper - olonok@hotmail_com', run_id='47b84e1d2f074a6b84ff1595368bed3a', run_link='', source='dbfs:/databricks/mlflow-tracking/2965825698891942/47b84e1d2f074a6b84ff1595368bed3a/artifacts/code_helper', status='READY', status_message='', tags={}, user_id='1491868126462402', version='4'>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.transition_model_version_stage(model_name, model_version, \"production\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks LLMOps 2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
