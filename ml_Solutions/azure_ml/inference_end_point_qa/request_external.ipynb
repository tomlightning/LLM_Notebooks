{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d821399-a194-4955-8549-33806970feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ecd1820-52ee-49ad-afdd-fa32773f686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5645dc8-781c-4874-a09b-95fbb39a7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3fa3ce5-b7e9-474c-b096-9f492b273e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/api/models/deepset/roberta-base-squad2\n",
      "{'_id': '621ffdc136468d709f17a5fd', 'id': 'deepset/roberta-base-squad2', 'modelId': 'deepset/roberta-base-squad2', 'author': 'deepset', 'sha': 'e84d19c1ab20d7a5c15407f6954cef5c25d7a261', 'lastModified': '2023-09-26T11:36:30.000Z', 'private': False, 'disabled': False, 'gated': False, 'pipeline_tag': 'question-answering', 'tags': ['transformers', 'pytorch', 'tf', 'jax', 'rust', 'safetensors', 'roberta', 'question-answering', 'en', 'dataset:squad_v2', 'license:cc-by-4.0', 'model-index', 'endpoints_compatible', 'has_space', 'region:us'], 'downloads': 1217829, 'library_name': 'transformers', 'mask_token': '<mask>', 'widgetData': [{'text': 'Where do I live?', 'context': 'My name is Wolfgang and I live in Berlin'}, {'text': 'Where do I live?', 'context': 'My name is Sarah and I live in London'}, {'text': \"What's my name?\", 'context': 'My name is Clara and I live in Berkeley.'}, {'text': 'Which name is also used to describe the Amazon rainforest in English?', 'context': 'The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet\\'s remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.'}], 'likes': 573, 'model-index': [{'name': 'deepset/roberta-base-squad2', 'results': [{'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squad_v2', 'type': 'squad_v2', 'config': 'squad_v2', 'split': 'validation'}, 'metrics': [{'type': 'exact_match', 'value': 79.9309, 'name': 'Exact Match', 'verified': True, 'verifyToken': 'eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiMDhhNjg5YzNiZGQ1YTIyYTAwZGUwOWEzZTRiYzdjM2QzYjA3ZTUxNDM1NjE1MTUyMjE1MGY1YzEzMjRjYzVjYiIsInZlcnNpb24iOjF9.EH5JJo8EEFwU7osPz3s7qanw_tigeCFhCXjSfyN0Y1nWVnSfulSxIk_DbAEI5iE80V4EKLyp5-mYFodWvL2KDA'}, {'type': 'f1', 'value': 82.9501, 'name': 'F1', 'verified': True, 'verifyToken': 'eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiMjk5ZDYwOGQyNjNkMWI0OTE4YzRmOTlkY2JjNjQ0YTZkNTMzMzNkYTA0MDFmNmI3NjA3NjNlMjhiMDQ2ZjJjNSIsInZlcnNpb24iOjF9.DDm0LNTkdLbGsue58bg1aH_s67KfbcmkvL-6ZiI2s8IoxhHJMSf29H_uV2YLyevwx900t-MwTVOW3qfFnMMEAQ'}, {'type': 'total', 'value': 11869, 'name': 'total', 'verified': True, 'verifyToken': 'eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiMGFkMmI2ODM0NmY5NGNkNmUxYWViOWYxZDNkY2EzYWFmOWI4N2VhYzY5MGEzMTVhOTU4Zjc4YWViOGNjOWJjMCIsInZlcnNpb24iOjF9.fexrU1icJK5_MiifBtZWkeUvpmFISqBLDXSQJ8E6UnrRof-7cU0s4tX_dIsauHWtUpIHMPZCf5dlMWQKXZuAAA'}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squad', 'type': 'squad', 'config': 'plain_text', 'split': 'validation'}, 'metrics': [{'type': 'exact_match', 'value': 85.289, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 91.841, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'adversarial_qa', 'type': 'adversarial_qa', 'config': 'adversarialQA', 'split': 'validation'}, 'metrics': [{'type': 'exact_match', 'value': 29.5, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 40.367, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squad_adversarial', 'type': 'squad_adversarial', 'config': 'AddOneSent', 'split': 'validation'}, 'metrics': [{'type': 'exact_match', 'value': 78.567, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 84.469, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squadshifts amazon', 'type': 'squadshifts', 'config': 'amazon', 'split': 'test'}, 'metrics': [{'type': 'exact_match', 'value': 69.924, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 83.284, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squadshifts new_wiki', 'type': 'squadshifts', 'config': 'new_wiki', 'split': 'test'}, 'metrics': [{'type': 'exact_match', 'value': 81.204, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 90.595, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squadshifts nyt', 'type': 'squadshifts', 'config': 'nyt', 'split': 'test'}, 'metrics': [{'type': 'exact_match', 'value': 82.931, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 90.756, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squadshifts reddit', 'type': 'squadshifts', 'config': 'reddit', 'split': 'test'}, 'metrics': [{'type': 'exact_match', 'value': 71.55, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 82.939, 'name': 'F1', 'verified': False}]}]}], 'config': {'architectures': ['RobertaForQuestionAnswering'], 'model_type': 'roberta', 'tokenizer_config': {}}, 'cardData': {'language': 'en', 'license': 'cc-by-4.0', 'datasets': ['squad_v2'], 'model-index': [{'name': 'deepset/roberta-base-squad2', 'results': [{'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squad_v2', 'type': 'squad_v2', 'config': 'squad_v2', 'split': 'validation'}, 'metrics': [{'type': 'exact_match', 'value': 79.9309, 'name': 'Exact Match', 'verified': True, 'verifyToken': 'eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiMDhhNjg5YzNiZGQ1YTIyYTAwZGUwOWEzZTRiYzdjM2QzYjA3ZTUxNDM1NjE1MTUyMjE1MGY1YzEzMjRjYzVjYiIsInZlcnNpb24iOjF9.EH5JJo8EEFwU7osPz3s7qanw_tigeCFhCXjSfyN0Y1nWVnSfulSxIk_DbAEI5iE80V4EKLyp5-mYFodWvL2KDA'}, {'type': 'f1', 'value': 82.9501, 'name': 'F1', 'verified': True, 'verifyToken': 'eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiMjk5ZDYwOGQyNjNkMWI0OTE4YzRmOTlkY2JjNjQ0YTZkNTMzMzNkYTA0MDFmNmI3NjA3NjNlMjhiMDQ2ZjJjNSIsInZlcnNpb24iOjF9.DDm0LNTkdLbGsue58bg1aH_s67KfbcmkvL-6ZiI2s8IoxhHJMSf29H_uV2YLyevwx900t-MwTVOW3qfFnMMEAQ'}, {'type': 'total', 'value': 11869, 'name': 'total', 'verified': True, 'verifyToken': 'eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiMGFkMmI2ODM0NmY5NGNkNmUxYWViOWYxZDNkY2EzYWFmOWI4N2VhYzY5MGEzMTVhOTU4Zjc4YWViOGNjOWJjMCIsInZlcnNpb24iOjF9.fexrU1icJK5_MiifBtZWkeUvpmFISqBLDXSQJ8E6UnrRof-7cU0s4tX_dIsauHWtUpIHMPZCf5dlMWQKXZuAAA'}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squad', 'type': 'squad', 'config': 'plain_text', 'split': 'validation'}, 'metrics': [{'type': 'exact_match', 'value': 85.289, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 91.841, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'adversarial_qa', 'type': 'adversarial_qa', 'config': 'adversarialQA', 'split': 'validation'}, 'metrics': [{'type': 'exact_match', 'value': 29.5, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 40.367, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squad_adversarial', 'type': 'squad_adversarial', 'config': 'AddOneSent', 'split': 'validation'}, 'metrics': [{'type': 'exact_match', 'value': 78.567, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 84.469, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squadshifts amazon', 'type': 'squadshifts', 'config': 'amazon', 'split': 'test'}, 'metrics': [{'type': 'exact_match', 'value': 69.924, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 83.284, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squadshifts new_wiki', 'type': 'squadshifts', 'config': 'new_wiki', 'split': 'test'}, 'metrics': [{'type': 'exact_match', 'value': 81.204, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 90.595, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squadshifts nyt', 'type': 'squadshifts', 'config': 'nyt', 'split': 'test'}, 'metrics': [{'type': 'exact_match', 'value': 82.931, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 90.756, 'name': 'F1', 'verified': False}]}, {'task': {'type': 'question-answering', 'name': 'Question Answering'}, 'dataset': {'name': 'squadshifts reddit', 'type': 'squadshifts', 'config': 'reddit', 'split': 'test'}, 'metrics': [{'type': 'exact_match', 'value': 71.55, 'name': 'Exact Match', 'verified': False}, {'type': 'f1', 'value': 82.939, 'name': 'F1', 'verified': False}]}]}]}, 'transformersInfo': {'auto_model': 'AutoModelForQuestionAnswering', 'pipeline_tag': 'question-answering', 'processor': 'AutoTokenizer'}, 'spaces': ['microsoft/HuggingGPT', 'seduerr/semantic_search', 'anakin87/who-killed-laura-palmer', 'razakhan/text-summarizer', 'AmazonScience/QA-NLU', 'Hellisotherpeople/HF-SHAP', 'taesiri/HuggingGPT-Lite', 'Eemansleepdeprived/Study_For_Me_AI', 'nsethi610/ns-gradio-apps', 'Wootang01/question_answer', 'raphaelsty/games', 'Abhilashvj/haystack_QA', 'manishjaiswal/05-SOTA-Question-Answer-From-TextFileContext-Demo', 'jayesh95/Voice-QA', 'IsmayilMasimov36/question-answering-app', 'awacke1/SOTA-Plan', 'jorge-henao/ask2democracy', 'awacke1/CarePlanQnAWithContext', 'AIZ2H/05-SOTA-Question-Answer-From-TextFileContext', 'drift-ai/question-answer-text', 'emmetmayer/Large-Context-Question-and-Answering', 'course-demos/question-answering-simple', 'unco3892/real_estate_ie', 'amsterdamNLP/attention-rollout', 'nkatraga/7.22.CarePlanQnAWithContext', 'Timjo88/toy-board-game-QA', 'HemanthSai7/IntelligentQuestionGenerator', 'awacke1/NLPContextQATransformersRobertaBaseSquad2', 'cyberspyde/chatbot-team4', 'edemgold/QA-App', 'gulabpatel/Question-Answering_roberta', 'cpnepo/Harry-Potter-Q-A', 'awacke1/ContextQuestionAnswerNLP', 'mishtert/tracer', 'niksyad/CarePlanQnAWithContext', 'awacke1/CarePlanQnAWithContext2', 'williambr/CarePlanSOTAQnA', 'sdande11/CarePlanQnAWithContext2', 'BilalSardar/QuestionAndAnswer', 'Jonni/05-QandA-from-textfile', 'Chatop/Lab10', 'Sasidhar/information-extraction-demo', 'cshallah/qna-ancient-1', 'awacke1/NLPDemo1', 'hhalim/NLPContextQATransformersRobertaBaseSquad2', 'allieannez/NLPContextQASquad2Demo', 'sanjayw/nlpDemo1', 'abhilashb/NLP-Test', 'ccarr0807/HuggingGPT', 'theholycityweb/HuggingGPT', 'camillevanhoffelen/langchain-HuggingGPT', 'saurshaz/HuggingGPT', 'Kelvinhjk/QnA_chatbot_for_Swinburne_cs_course', 'Th3BossC/TranscriptApi', 'Jaehan/Question-Answering-1', 'knotmesh/deepset-roberta-base-squad2', 'Nikhil0987/omm', 'Manoj21k/Custom-QandA', 'aidinro/qqqqqqqqqqqqq', 'roshithindia/ayureasybot', 'MachineLearningReply/search_mlReply', 'Alfasign/HuggingGPT-Lite', 'AyselRahimli/Project2', 'abidlabs/question-answering', 'aidan-o-brien/recipe-improver', 'bentrevett/question-answering', 'stmnk/patchface', 'abidlabs/question-answering-simple', 'utec/SpaceLucasAlmeida', 'abidlabs/question-answering-demo', 'abidlabs/quick-qa', 'docs-demos/roberta-base-squad2', 'clevo570/Nissan_Project', 'ziyadbastaili/get_special_meeting', 'charlesfrye/test-space-117', 'yadapruk/document-qa', 'cpnepo/DFA_Press_Release_QnA', 'PRENT/PR-ENT_Dashboard', 'peter2000/policy_test', 'atomiclabs/question_answering', 'noelfranthomas/LabBot', 'Lurunchik/nf-cats', 'jaydeepkum/CarePlanQnaWithContext', 'santoshsindham/CarePlanQnAWithContext', 'Myrna/CarePlan', 'PrafulUHG/CarePlan', 'Desh/test1', 'SudarshanaR/CarePlanQnaWithContext', 'Preetesh/CarePlanQnAWithContext', 'awacke1/CarePlanSOTAQnA', 'peekaboo/CarePlanQnA', 'Vasanthp/CarePlanSOTAQnA', 'vnemala/CarePlanSOTAQnA', 'ocordes/CarePlanSOTAQnA', 'mm2593/CarePlan', 'MateusA/CarePlanSOTAQnA', 'vsaripella/CarePlanSOTAQnA', 'MadhuV28/SOTA-Plan', 'madara-uchiha/CarePlanQnAContext', 'burhanaminvaid/CarePlanQnAWithContext', 'rsatish1110/CareplanQnAwithContext', 'Sasidhar/ml-playground', 'Priyabrata017/CarePlanQnAWithContext', 'freddyaboulton/all_demos', 'Jai12345/kendra', 'Saliltrehan7/deepset_roberta-base-squad2', 'tomcat/AskAndAnswer', 'tomcat/Ask_and_Answer_v2', 'shawon100/context-question-answering', 'Timjo88/monopoly-qa-semantic-search', 'pjain/StreamlitBasicQA', 'krrishD/deepset_roberta-base-squad2', 'clef/PRENT-Demo', 'p208p2002/Transformer-QA-Decode-Visualize', 'abidlabs/qa', 'rajamamoon/Studyforme', 'jaimin/Bullet_Point', 'HilaMarcus/Hila', 'Ahmedshabana/QA-Sapce', 'Charmaine/qna', 'Harsh23Kashyap/QnA-System', 'vissu27/deepset-roberta-base-squad2', 'myeh/QuestionandAnswering', 'myeh/QA', 'plasticlabs/qa-prototype-roberta', 'Carlosito16/Artinity_bot', 'LeoGitGuy/BounWiki', 'subrota2k2/qa_roberta', 'sbudni/sk', 'LeoGitGuy/BounWikiQA', 'davidnai/qa_roberta', 'sharetest2000/qa_roberta', 'adrien1/test1', 'VasMir/deepset-roberta-base-squad2', 'madani/qa_roberta', 'stmnk/mlrefsqa', 'Joom/deepset-roberta-base-squad2', 'Everymans-ai/GPT3-knowledge-management', 'srimali1234/deepset-roberta-base-squad2', 'vanishing-grad/sense', 'eruizgar91/test-Haystack', 'y595086081/learninguse', 'vincentclaes/question-answer-text', 'sedrickkeh/vqa-guessing-game', 'sohailq/space1', 'cbb0214/jiangjiang_mama', 'SelinSekmen/deepset-roberta-base-squad2', 'ethanrom/chat2', 'nassga/Question_answer', 'JeffMao/sp1', 'omprakash93/om_test', 'Louise1001/qa_roberta', 'Dochee/QA_berta', 'Betacuckgpt/deepset-roberta-base-squad2', 'ChunHo/TfNLP', 'jmartinezot/berteus_test', 'raghuram13/deepset', 'kanishka207004/Document_QA', 'mydisposable/bloodfire', 'rambocoder/t1000', 'EricCao/deepset-roberta-base-squad2', 'keaneu/HuggingGPT', 'viscosity/HuggingGPT', 'Mcdof/HuggingGPT', 'BMukhtar/BMA', 'chrisW6825/HuggingGPT', 'Shenziqian/HuggingGPT', 'lokutus/HuggingGPT', 'mimiqiao/HuggingGPT', 'tsgbalakarthik/HuggingGPT', 'wowochkin/HuggingGPT', 'Msp/HuggingGPT', 'sam12321/deepset-roberta-base-squad2', 'ryan12439/HuggingGPTpub', 'FANCHIYU/HuggingGPT', 'Betacuckgpt/HuggingGPT', 'cashqin/HuggingGPT', 'felixfriday/MICROSOFTT_JARVIS_HuggingGPT', 'Meffordh/HuggingGPT', 'lzqfree/HuggingGPT', 'bountyfuljr/HuggingGPTplaypublic', 'mearjunsha/HuggingGPT', 'turbowed/HuggingGPT', 'Chokyounghoon/HuggingGPT', 'JoeMattAI/deepset-roberta-base-squad2', 'lollo21/Will-GPT', 'Pfs2021Funny/HuggingGPT', 'irritablebro/HuggingGPT', 'MagKoz/HuggingGPT', 'zhangdream/HuggingGPT', 'calliber/HuggingGPT', 'Pitak/HuggingGPT', 'gaocegege/HuggingGPT', 'jmsdatasci/textasdata', 'apgarmd/jarvis', 'apgarmd/jarvis2', 'mukulnag/HuggingGPT1', 'Jaggi/deepset-roberta-base-squad2', 'lugifudun/HuggingGPT', 'leadmaister/HuggingGPT', 'pors/HuggingGPT', 'diogocarapito/chatmgf', 'vs4vijay/HuggingGPT', 'dabbu2000/FinetunedLanguageModel', 'mckeeboards/HuggingGPT', 'mastere00/JarvisMeetsProfessor', 'passthebutter/HuggingGPT', 'manu1435/HuggingGPT', 'laohudajinwan/deepset-roberta-base-squad2', 'RiyaChougule/Question-Answer-model', 'NaamanSaif/HuggingGPT', 'CollaalloC/HuggingGPT', 'dwolfe66/HuggingGPT', 'xian-sheng/HuggingGPT', 'skid-dev/deepset-roberta-base-squad2', 'PSM272/WikiAI', 'Aygtljl518866/HuggingGPT', 'arthi-96/Ponniyin-Selvan-Chatbot', 'Hemi1403/HuggingGPT', 'osanseviero/all_nlp_demos', 'Ekruders/deepset-roberta-base-squad2', 'trhacknon/HuggingGPT', 'Vito99/HuggingGPT-Lite', 'EinfachOlder/HuggingGPT-Lite', 'Ickbert/gradio_2', 'innovativeillusions/HuggingGPT', 'vamgan/deepset-roberta-base-squad2', 'florymignon/biuma', 'Namit2111/QA', 'CazimirRoman/ChatGPTWithWikipedia', 'nitin77/deepset-roberta-base-squad2', 'ttphong68/code_5.1', 'vasevooo/NLP_project', 'annafilina/NLP_project', 'ramanakumark/CarePlanQnAWithContext', 'leFalcon/mi_primer_llm', 'chillerie/api-test', 'InvictusRudra/question_answering', 'fdogmz/qa_test', 'prlabs2023/question-answere-1', 'ylavie/HuggingGPT3', 'ylavie/HuggingGPT-Lite', 'yewsam1277/question-answering-malaysia', 'Kelvinhjk/demo1', 'Diuyilu/qa_roberta', 'edjdhug3/chatbot-1', 'mdsadiq/deepset-roberta-base-squad2', 'CCYAO/HuggingGPT', 'wangkq1/nlp_test', 'talentyu/talent_yu_ai', 'jarvis911/deepset-roberta-base-squad2', 'TuTM/NLP_Project', 'kunitakayama/startup', 'jeromyyap/deepset-roberta-base-squad2', 'peanut007/qa_roberta', 'matthartman/PDFreader', 'awl2023/deepset-roberta-base-squad2', 'hwayo/qa_roberta', 'nalanwutuo/test01', 'shahidkarimi/deepset-roberta-base-squad2', 'dcams/HuggingGPT', 'RosyTchoumi/squad_demo', '9farccontioshi/TranscriptApi', 'Vaishali12/docVQA_demo', 'xlinsdo/deepset-roberta-base-squad2', 'Seb230/QA_Model', 'Seb230/Model_Demo', 'rt22/deepset-roberta-base-squad2', 'arpitneema/ArpitRobertaBase', 'jingwora/language-question-answering', 'Mapleie/deepset-roberta-base-squad2', 'Jafta/Roberta-QnA', 'Lucastil2212/ufo-intel', 'zapliance/deepset-roberta-base-squad2', 'kalyansworld/Question-Answer', 'exyou/talk_to_project_nexodus', 'cndavy/HuggingGPT', 'yaoqi/question-answering-simple', 'prasannakram/deepset-roberta-base-squad2', 'lucas-w/deepset-roberta-base-squad2', 'bluequijote/qa_robera2', 'ankitMzluri/deepset-roberta-base-squad2', 'rganesan2003/laksam', 'wtlu88/qa_roberta', 'tianboguang/kuqin0905-02', 'DineshDyne/QA_test', 'Ono-Enzo/test-space', 'abishek-official/Legal-doc-Summarizer', 'umair894/fastapi-document-qa_plus', 'umair894/fastapi-document-qa_semantic', 'WilliamArias/deepset-roberta-base-squad2', 'hf-dongpyo/qa_roberta', 'Krrish4757/deepset-roberta-base-squad2', 'jcherrya/little_qna', 'subu4444/basic-nlp-operations', 'inumulaisk/deepset-roberta-base-squad2', 'makanaiii/text-summarizer-dublicated', 'donohara-cmweb/oreilly', 'Rohankumar31/Prakruti_LLM', 'gdlunga/halloween-unibo-2023', 'Manoj21k/Conversational_QandA', 'Anavya1/text-summarizer', 'rawezh/deepset-roberta-base-squad2', 'rm92/test_hf_rm', 'ZackBradshaw/omni_bot', 'ketangandhi/my-bot', 'jayant-yadav/deepset-roberta-base-squad2', 'cryptokid2017/deepset-roberta-base-squad2', 'hiert/deepset-roberta-base-squad2', 'VivekRastogi/deepset-roberta-base-squad2', 'jackwang2023/qa_roberta', 'Dzaecko/deepset-roberta-base-squad2', 'Iosif24/qa_roberta', 'Jforeverss/finchat222', 'nsjzg/hotdog-gradio', 'AashishKumar/deepset-roberta-base-squad2', 'alexvaroz/first_qa_roberta', 'dkbs12/Extractive-QA', 'Tedjoulemo/demo_app', 'mdkhalid/deepset-roberta-base-squad2', 'elvisklester/deepset-roberta-base-squad2', 'homeway/PromptCARE', 'Nikhil0987/wolf', 'AhmedMagdy7/deepset-roberta-base-squad2', 'KakuOG89/deepset-roberta-base-squad2', 'MJobe/document-vqa-v2', 'bari135/deepset-roberta-base-squad2', 'tracinginsights/QuotesBot', 'JK-TK/practice', 'yushaobin/deepset-roberta-base-squad2', 'AsadullaH777/HuggingGPT', 'Samira21/QA', 'herMaster/QnA-with-roberta-base-squad2', 'Psychophoria/deepset-roberta-base-squad2', 'priyanshu027/deepset-roberta-base-squad2', 'fsaglam2002/qa_roberta', 'Charles95/gradio-tasks', 'yugamj/Finance_chatbot', 'mindmime/gradio', 'caovantuan/ai255', 'deadeye0/druginfoextractor', 'anshrochan/deepset-roberta-base-squad2', 'run480/intro_to_transformers', 'gmpravin/deepset-roberta-base-squad2', 'watt-wiz/deepset-roberta-base-squad2', 'Ahmadzei/RAG', 'jaredlafitte/QC', 'GowthamYarlagadda/ContextQuestionAnswerNLP', 'mikepastor11/PennwickHoneybeeRobot', 'snehh/task_1', 'mkkumar/mkk', 'mohamed20d/deepset-roberta-base-squad2'], 'safetensors': {'parameters': {'F32': 124056578, 'I64': 514}, 'total': 124057092}, 'siblings': [{'rfilename': '.gitattributes'}, {'rfilename': 'README.md'}, {'rfilename': 'config.json'}, {'rfilename': 'flax_model.msgpack'}, {'rfilename': 'merges.txt'}, {'rfilename': 'model.safetensors'}, {'rfilename': 'pytorch_model.bin'}, {'rfilename': 'rust_model.ot'}, {'rfilename': 'special_tokens_map.json'}, {'rfilename': 'tf_model.h5'}, {'rfilename': 'tokenizer_config.json'}, {'rfilename': 'vocab.json'}], 'createdAt': '2022-03-02T23:29:05.000Z'}\n"
     ]
    }
   ],
   "source": [
    "# Get the model object from HuggingFaceHub. We can use it to check for sample test data\n",
    "import urllib.request, json\n",
    "\n",
    "raw_data = urllib.request.urlopen(\n",
    "    \"https://huggingface.co/api/models/\" + 'deepset/roberta-base-squad2'\n",
    ")\n",
    "\n",
    "print(\"https://huggingface.co/api/models/\" + 'deepset/roberta-base-squad2')\n",
    "data = json.load(raw_data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8029b702-40b4-4cdb-8495-4df7b10b5298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'id', 'modelId', 'author', 'sha', 'lastModified', 'private', 'disabled', 'gated', 'pipeline_tag', 'tags', 'downloads', 'library_name', 'mask_token', 'widgetData', 'likes', 'model-index', 'config', 'cardData', 'transformersInfo', 'spaces', 'safetensors', 'siblings', 'createdAt'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dddf208b-d85b-41d8-a0f9-1c6ac5b0c52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Where do I live?',\n",
       "  'context': 'My name is Wolfgang and I live in Berlin'},\n",
       " {'text': 'Where do I live?',\n",
       "  'context': 'My name is Sarah and I live in London'},\n",
       " {'text': \"What's my name?\",\n",
       "  'context': 'My name is Clara and I live in Berkeley.'},\n",
       " {'text': 'Which name is also used to describe the Amazon rainforest in English?',\n",
       "  'context': 'The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet\\'s remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['widgetData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0dba8c7-f4e3-40fb-b311-cb5b0e58efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab373172-38b4-46d8-ae16-6e375d8704ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = config.get(\"KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf364cac-08b9-4463-ab76-3aae5352e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# The example below assumes JSON formatting which may be updated\n",
    "# depending on the format your endpoint expects.\n",
    "# More information can be found here:\n",
    "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "data = {\n",
    "  \"inputs\": {\n",
    "    \"question\": \"Which name is also used to describe the Amazon rainforest in English?\",\n",
    "    \"context\": \"The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain 'Amazonas' in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\",\n",
    "  }\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dfae3c9-163f-44a6-8bf2-22fe541456af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"score\":0.7497807741165161,\"start\":201,\"end\":230,\"answer\":\"Amazonia or the Amazon Jungle\"}'\n"
     ]
    }
   ],
   "source": [
    "url = 'https://question-answering-1709667031.uksouth.inference.ml.azure.com/score'\n",
    "# https://question-answering-1709656967.uksouth.inference.ml.azure.com/score\n",
    "# Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "if not api_key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'test-qa' }\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53dbfdd5-ed9c-48bd-80fe-4e6af10fa049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"score\":0.7497807741165161,\"start\":201,\"end\":230,\"answer\":\"Amazonia or the Amazon Jungle\"}\n"
     ]
    }
   ],
   "source": [
    "print(result.decode(\"utf8\", 'ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0653b20-578c-46f8-8800-4553d68668f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (azure_ml)",
   "language": "python",
   "name": "azure_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
