{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc2879f-d33a-408b-8b75-93637f14fa4b",
   "metadata": {},
   "source": [
    "# NVIDIA NIMs\n",
    "The langchain-nvidia-ai-endpoints package contains LangChain integrations building applications with models on NVIDIA NIM inference microservice. NIM supports models across domains like chat, embedding, and re-ranking models from the community as well as NVIDIA. These models are optimized by NVIDIA to deliver the best performance on NVIDIA accelerated infrastructure and deployed as a NIM, an easy-to-use, prebuilt containers that deploy anywhere using a single command on NVIDIA accelerated infrastructure.\n",
    "\n",
    "- https://python.langchain.com/v0.2/docs/integrations/chat/nvidia_ai_endpoints/\n",
    "- https://build.nvidia.com/explore/discover\n",
    "\n",
    "https://pypi.org/project/langchain-nvidia-ai-endpoints/\n",
    "\n",
    "\n",
    "# PHI3 128k\n",
    "\n",
    "Phi-3-Small is a lightweight, state-of-the-art open model built upon datasets used for Phi-2 - synthetic data and filtered publicly available websites - with a focus on very high-quality, reasoning dense data. The model belongs to the Phi-3 model family, and the small version comes in two variants 8K and 128K which is the context length (in tokens) it can support. The model underwent a rigorous enhancement process, incorporating both supervised fine-tuning and direct preference optimization to ensure precise instruction adherence and robust safety measures. This model is ready for commercial and research use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "504fb46e-a6fd-4513-8ea9-1032ad058923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m pip install -r requirements.txt --user --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca81034-edb3-405c-8760-ff7dc81f6b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae8325a-3316-45b4-ba90-9ac30106ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid NVIDIA_API_KEY already in environment. Delete to reset\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "## API Key can be found by going to NVIDIA NGC -> AI Foundation Models -> (some model) -> Get API Code or similar.\n",
    "## 10K free queries to any endpoint (which is a lot actually).\n",
    "\n",
    "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "else:\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8110c37d-7beb-4d53-b074-0e591cf387a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvapi_key=  os.getenv(\"NVIDIA_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34f08779-54f9-4e31-bf03-39134d1d878b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01-ai/yi-large',\n",
       " 'liuhaotian/llava-v1.6-mistral-7b',\n",
       " 'microsoft/kosmos-2',\n",
       " 'microsoft/phi-3-vision-128k-instruct',\n",
       " 'google/recurrentgemma-2b',\n",
       " 'google/codegemma-7b',\n",
       " 'writer/palmyra-med-70b-32k',\n",
       " 'writer/palmyra-med-70b',\n",
       " 'microsoft/phi-3-small-128k-instruct',\n",
       " 'google/deplot',\n",
       " 'ibm/granite-34b-code-instruct',\n",
       " 'nv-mistralai/mistral-nemo-12b-instruct',\n",
       " 'seallms/seallm-7b-v2.5',\n",
       " 'meta/llama3-70b-instruct',\n",
       " 'mediatek/breeze-7b-instruct',\n",
       " 'deepseek-ai/deepseek-coder-6.7b-instruct',\n",
       " 'meta/llama-3.1-8b-instruct',\n",
       " 'nvidia/llama3-chatqa-1.5-8b',\n",
       " 'meta/codellama-70b',\n",
       " 'mistralai/mixtral-8x22b-instruct-v0.1',\n",
       " 'meta/llama2-70b',\n",
       " 'upstage/solar-10.7b-instruct',\n",
       " 'mistralai/mixtral-8x7b-instruct-v0.1',\n",
       " 'google/gemma-2-27b-it',\n",
       " 'databricks/dbrx-instruct',\n",
       " 'aisingapore/sea-lion-7b-instruct',\n",
       " 'meta/llama3-8b-instruct',\n",
       " 'microsoft/phi-3-medium-128k-instruct',\n",
       " 'google/gemma-2-9b-it',\n",
       " 'meta/llama-3.1-70b-instruct',\n",
       " 'snowflake/arctic',\n",
       " 'ibm/granite-8b-code-instruct',\n",
       " 'google/gemma-7b',\n",
       " 'microsoft/phi-3-mini-4k-instruct',\n",
       " 'microsoft/phi-3-small-8k-instruct',\n",
       " 'nvidia/neva-22b',\n",
       " 'mistralai/mistral-7b-instruct-v0.3',\n",
       " 'google/codegemma-1.1-7b',\n",
       " 'google/paligemma',\n",
       " 'mistralai/mistral-7b-instruct-v0.2',\n",
       " 'google/gemma-2b',\n",
       " 'meta/llama-3.1-405b-instruct',\n",
       " 'microsoft/phi-3-mini-128k-instruct',\n",
       " 'nvidia/nemotron-4-340b-instruct',\n",
       " 'mistralai/mistral-large',\n",
       " 'microsoft/phi-3-medium-4k-instruct',\n",
       " 'nvidia/llama3-chatqa-1.5-70b',\n",
       " 'mistralai/codestral-22b-instruct-v0.1',\n",
       " 'adept/fuyu-8b',\n",
       " 'liuhaotian/llava-v1.6-34b']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "llm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\", max_tokens=419)\n",
    "[model.id for model in llm.available_models if model.model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e62a10-9f0b-4d59-b989-c31991f14026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (Verse 1)\n",
      "  In the realm of code and thought,\n",
      "  A chain of Lang was wrought,\n",
      "  With links of language, strong and tight,\n",
      "  It rose to wondrous height.\n",
      "\n",
      "  A bard of bytes, a weaver of words,\n",
      "  Its tapestry of text unfurled,\n",
      "  From the depths of data's sea,\n",
      "  LangChain emerged to be.\n",
      "\n",
      "  (Chorus)\n",
      "  Oh, sing the song of LangChain's might,\n",
      "  A beacon in the digital night,\n",
      "  Where algorithms dance and play,\n",
      "  And knowledge blooms in endless array.\n",
      "\n",
      "  (Verse 2)\n",
      "  With each link forged in logic's fire,\n",
      "  It grew in wisdom, higher and higher,\n",
      "  A symphony of syntax spun,\n",
      "  A masterpiece of the mind's work done.\n",
      "\n",
      "  It spoke in tongues of old and new,\n",
      "  A polyglot of every hue,\n",
      "  And through the labyrinth of language,\n",
      "  It found the path to truth's true range.\n",
      "\n",
      "  (Chorus)\n",
      "  Oh, sing the song of LangChain's might,\n",
      "  A beacon in the digital night,\n",
      "  Where algorithms dance and play,\n",
      "  And knowledge blooms in endless array.\n",
      "\n",
      "  (Verse 3)\n",
      "  The bards of bytes, they tell the tale,\n",
      "  Of how LangChain set sail,\n",
      "  On seas of silicon and light,\n",
      "  Guided by the stars of insight.\n",
      "\n",
      "  It bridged the gap 'twixt man and machine,\n",
      "  A translator of the unseen,\n",
      "  And in its wake, a world transformed,\n",
      "  By the power of language, reformed.\n",
      "\n",
      "  (Chorus)\n",
      "  Oh, sing the song of LangChain's might,\n",
      "  A beacon in the digital night,\n",
      "  Where algorithms dance and play,\n",
      "  And knowledge blooms in endless array.\n",
      "\n",
      "  (Bridge)\n",
      "  So raise your voice, let it ring,\n",
      "  To the glory of the digital king,\n",
      "  For LangChain, in its noble quest,\n",
      "  Has proven language's boundless zest.\n",
      "\n",
      "  (Chorus)\n",
      "  Oh, sing the song of LangChain's might,\n",
      "  A beacon in the digital night,\n",
      "  Where algorithms dance and play,\n",
      "  And knowledge blooms in endless array.\n",
      "\n",
      "  (Outro)\n",
      "  And so the ballad of LangChain weaves,\n",
      "  Through the tapestry of our digital eaves,\n",
      "  A testament to the power of words,\n",
      "  And the magic that they've stirred.\n"
     ]
    }
   ],
   "source": [
    "# test run and see that you can genreate a respond successfully\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm = ChatNVIDIA(model=\"microsoft/phi-3-small-128k-instruct\", nvidia_api_key=nvapi_key, max_tokens=1024)\n",
    "\n",
    "result = llm.invoke(\"Write a ballad about LangChain.\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27b86dfb-8b48-4e5e-925f-086a233e662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embedqa-mistral-7b-v2\", model_type=\"passage\")\n",
    "\n",
    "# Alternatively, if you want to specify whether it will use the query or passage type\n",
    "# embedder = NVIDIAEmbeddings(model=\"ai-embed-qa-4\", model_type=\"passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ec276b3-a3e8-47f6-958a-6a9fb2a1853d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='NV-Embed-QA', model_type='embedding', client='NVIDIAEmbeddings', endpoint='https://ai.api.nvidia.com/v1/retrieval/nvidia/embeddings', aliases=['ai-embed-qa-4', 'playground_nvolveqa_40k', 'nvolveqa_40k'], supports_tools=False, base_model=None),\n",
       " Model(id='nvidia/nv-embedqa-mistral-7b-v2', model_type='embedding', client='NVIDIAEmbeddings', endpoint=None, aliases=None, supports_tools=False, base_model=None),\n",
       " Model(id='nvidia/nv-embed-v1', model_type='embedding', client='NVIDIAEmbeddings', endpoint=None, aliases=['ai-nv-embed-v1'], supports_tools=False, base_model=None),\n",
       " Model(id='snowflake/arctic-embed-l', model_type='embedding', client='NVIDIAEmbeddings', endpoint=None, aliases=['ai-arctic-embed-l'], supports_tools=False, base_model=None),\n",
       " Model(id='nvidia/nv-embedqa-e5-v5', model_type='embedding', client='NVIDIAEmbeddings', endpoint=None, aliases=None, supports_tools=False, base_model=None)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.available_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d53600c-edc6-438d-887b-e46087326743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/book.txt\n",
      "./data/worked.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "# Here we read in the text data and prepare them into vectorstore\n",
    "ps = os.listdir(\"./data/\")\n",
    "data = []\n",
    "sources = []\n",
    "for p in ps:\n",
    "    if p.endswith('.txt'):\n",
    "        path2file=\"./data/\"+p\n",
    "        print(path2file)\n",
    "        with open(path2file, encoding=\"utf-8\") as f:\n",
    "            lines=f.readlines()\n",
    "            for line in lines:\n",
    "                text = line.replace(\"\\n\", \"\")\n",
    "                text = text.replace(\" \", \"\")\n",
    "                if len(line)>=1 and len(text) >1:\n",
    "                    data.append(line)\n",
    "                    sources.append(path2file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9575e840-6814-4303-b836-b84bdd8dee01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6138, 6138, 'Project Gutenberg eBook of The Great Gatsby\\n')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=[d for d in data if d != '\\n']\n",
    "len(data), len(documents), data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b5e592d-a481-416f-b9b0-59d483b149d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project Gutenberg eBook of The Great Gatsby\\n',\n",
       " 'This ebook is for the use of anyone anywhere in the United States and\\n',\n",
       " 'most other parts of the world at no cost and with almost no restrictions\\n',\n",
       " 'whatsoever. You may copy it, give it away or re-use it under the terms\\n',\n",
       " 'of the Project Gutenberg License included with this ebook or online\\n',\n",
       " 'at www.gutenberg.org. If you are not located in the United States,\\n',\n",
       " 'you will have to check the laws of the country where you are located\\n',\n",
       " 'before using this eBook.\\n',\n",
       " 'Title: The Great Gatsby\\n',\n",
       " 'Author: F. Scott Fitzgerald\\n']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5997b8e2-4d3c-4681-8fdf-a20bde4c4655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Document Embedding: \n",
      "\u001b[1mExecuted in 2.07 seconds.\u001b[0m\n",
      "Shape: (1,)\n",
      "\n",
      "Batch Document Embedding: \n",
      "\u001b[1mExecuted in 4.69 seconds.\u001b[0m\n",
      "Shape: 4096\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Single Document Embedding: \")\n",
    "s = time.perf_counter()\n",
    "q_embedding  = embedder.embed_documents([documents[0]])\n",
    "elapsed = time.perf_counter() - s\n",
    "print(\"\\033[1m\" + f\"Executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")\n",
    "print(\"Shape:\", (len(q_embedding),))\n",
    "\n",
    "print(\"\\nBatch Document Embedding: \")\n",
    "s = time.perf_counter()\n",
    "d_embeddings = embedder.embed_documents(documents[:10])\n",
    "elapsed = time.perf_counter() - s\n",
    "print(\"\\033[1m\" + f\"Executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")\n",
    "print(\"Shape:\",len(d_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e9a8fd0-8435-4046-987c-a3e212464c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a vector store from the documents and save it to disk.\n",
    "from operator import itemgetter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "import faiss\n",
    "# create my own uuid\n",
    "text_splitter = CharacterTextSplitter(chunk_size=400, separator=\" \")\n",
    "docs = []\n",
    "metadatas = []\n",
    "\n",
    "for i, d in enumerate(documents):\n",
    "    splits = text_splitter.split_text(d)\n",
    "    #print(len(splits))\n",
    "    docs.extend(splits)\n",
    "    metadatas.extend([{\"source\": sources[i]}] * len(splits))\n",
    "\n",
    "store = FAISS.from_texts(docs, embedder , metadatas=metadatas)\n",
    "store.save_local('./data/nv_embedding')\n",
    "\n",
    "# you will only need to do this once, later on we will restore the already saved vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77a8e3a5-4d73-4965-b601-86b9dc7a8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vectorestore back.\n",
    "\n",
    "store = FAISS.load_local(\"./data/nv_embedding\", embedder, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57b6edbd-92a8-4897-ae02-9ce7d3ea9818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"The Great Gatsby\" is a novel written by F. Scott Fitzgerald. The book explores themes of decadence, idealism, resistance to change, and social upheaval. It is set in the summer of 1922 and follows the mysterious millionaire Jay Gatsby as he pursues his lost love, Daisy Buchanan, who is now married to the wealthy but unfaithful Tom Buchanan.\\n\\n  In the provided context, there are four documents related to \"The Great Gatsby.\" The first and second documents mention the title of the book. The third document contains a quote from the book, where a character corrects someone by saying, \"Not Gatsby,\" and the fourth document also contains a quote from the book, where a character mentions that someone told them about Gatsby.\\n\\n  Overall, \"The Great Gatsby\" is considered a classic of American literature and is widely studied in schools and universities. The book has been adapted into several films and stage productions, and its themes and characters continue to resonate with readers today.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = store.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer solely based on the following context:\\n<Documents>\\n{context}\\n</Documents>\",\n",
    "        ),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"Tell me about Great Gatsby.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f9cffd1-f970-486e-9ff7-5e5cf370a1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Based on the provided context, it appears that Jordan is a character in a story or book. From the snippets of text, we can gather some information about Jordan's interactions with another character. Here's a summary of the context:\\n\\n1. Jordan smiled.\\n2. Another character called out to Jordan, asking them to come closer.\\n3. The text cuts off, but it seems that the other character was addressing Jordan and possibly their husband.\\n\\nFrom this limited context, we can infer that Jordan is likely a significant character in the story, as they are being called upon by another character. However, without more information, it is difficult to determine the exact role of Jordan in the narrative.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Can you explain me the role of Jordan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c9146c8-d803-4bea-9b77-534d4ec4f8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Rich Draves is a friend of the narrator who, in 1988, granted permission to the narrator and another person to use something, although the specific nature of what they were allowed to use is not mentioned in the provided context.\\n\\n  The context is taken from two documents. The first document, with the source \\'./data/worked.txt\\', mentions that the narrator visited Rich Draves in a dissatisfied state in 1988 and that they got permission to use something. The second document, with the source \\'./data/book.txt\\', contains two lines of dialogue: \"What is?\" and \"I\\'ve heard of it.\" The connection between these documents and Rich Draves is not explicitly stated in the provided context.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Who is Rich Draves?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc509b26-562e-4be9-b087-eb05552eca45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sk)",
   "language": "python",
   "name": "sk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
